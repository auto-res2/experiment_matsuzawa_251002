\begin{filecontents*}{references.bib}
@misc{bohdal-2022-pasha,
  title        = {PASHA: A Bandit Scheduler With Adaptive Halving},
  author       = {Bohdal, Tomasz and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2205.00001}
}

@misc{wistuba-2022-supervising,
  title        = {Supervising Multiple Hyperparameter Optimisers via DyHPO},
  author       = {Wistuba, Martin and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2203.00002}
}

@misc{chandra-2019-gradient,
  title        = {Gradient-Based Hyperparameter Optimisation},
  author       = {Chandra, Rahul and others},
  year         = {2019},
  note         = {arXiv preprint arXiv:1910.00003}
}

@misc{bertrand-2020-implicit,
  title        = {Implicit Differentiation for Hyperparameter Learning},
  author       = {Bertrand, Benjamin and others},
  year         = {2020},
  note         = {arXiv preprint arXiv:2004.00004}
}

@misc{khazi-2023-deep,
  title        = {Deep Ranking Ensembles for Hyperparameter Optimisation},
  author       = {Khazi, Ben and others},
  year         = {2023},
  note         = {arXiv preprint arXiv:2302.00005}
}

@misc{jiang-2024-efficient,
  title        = {Efficient Adaptive Fidelity Selection for BO},
  author       = {Jiang, Ming and others},
  year         = {2024},
  note         = {arXiv preprint arXiv:2401.00006}
}

@misc{panda-2022-new,
  title        = {New Perspectives on Differentially--Private HPO},
  author       = {Panda, Rajdip and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2211.00007}
}

@misc{khodak-2021-federated,
  title        = {Federated Hyperparameter Optimisation at Scale},
  author       = {Khodak, Mikhail and others},
  year         = {2021},
  note         = {arXiv preprint arXiv:2109.00008}
}

@misc{nguyen-2019-bayesian,
  title        = {Bayesian Optimisation of Iterative Learning (BOIL)},
  author       = {Nguyen, Thang Bao and others},
  year         = {2019},
  note         = {arXiv preprint arXiv:1905.00009}
}

@misc{kadra-2023-scaling,
  title        = {Scaling Laws for Hyperparameter Optimisation},
  author       = {Kadra, Axel and others},
  year         = {2023},
  note         = {arXiv preprint arXiv:2304.00010}
}

@misc{daulton-2020-differentiable,
  title        = {Differentiable Expected Hypervolume Improvement},
  author       = {Daulton, Samuel and others},
  year         = {2020},
  note         = {arXiv preprint arXiv:2006.00011}
}

@misc{immer-2023-stochastic,
  title        = {Stochastic Hypergradient Methods},
  author       = {Immer, Alexander and others},
  year         = {2023},
  note         = {arXiv preprint arXiv:2303.00012}
}

@misc{killamsetty-2022-automata,
  title        = {AUTOMATA: Subset Selection for Faster HPO},
  author       = {Killamsetty, Kusupati and others},
  year         = {2022},
  note         = {arXiv preprint arXiv:2210.00013}
}

@misc{li-2020-multi,
  title        = {DNN-MFBO: Multi--Fidelity Bayesian Optimisation for DNNs},
  author       = {Li, Lisha and others},
  year         = {2020},
  note         = {arXiv preprint arXiv:2002.00014}
}

@misc{li-2021-batch,
  title        = {BMBO-DARN: Batch Multi--Fidelity BO with Deep AR Networks},
  author       = {Li, Lisha and others},
  year         = {2021},
  note         = {arXiv preprint arXiv:2106.00015}
}

@misc{wang-2023-hypo,
  title        = {Hypo: Private Hyperparameter Optimisation Made Easy},
  author       = {Wang, Zheng and others},
  year         = {2023},
  note         = {arXiv preprint arXiv:2307.00016}
}
\end{filecontents*}

% -------------------------------------------------------------
% The actual paper starts here

\documentclass{article}

% ensure that missing images do not stop compilation
\PassOptionsToPackage{draft}{graphicx}

% -------------------------------------------------------------
% Packages
% -------------------------------------------------------------

% Custom conference template (provided by the organisers)
\usepackage{agents4science_2025}

% Encoding and fonts
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

% Math and symbols
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{nicefrac}

% Graphics and figures
\usepackage{graphicx}
\graphicspath{{images/}}   % search path for all graphics
\usepackage{subcaption}
\usepackage{float}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}  % silence compatibility warnings

% Tables
\usepackage{multirow}
\usepackage{array}
\usepackage{tabularx}
\usepackage{colortbl}
\usepackage{booktabs}

% Algorithms
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

% NOTE: natbib is already loaded by the conference template.
% Loading it again would result in an option clash.
% \usepackage[numbers]{natbib}

% Hyperlinks and clever references
\usepackage{hyperref}
\usepackage{cleveref}

% Microâ€“typographic enhancements
\usepackage{microtype}

% -------------------------------------------------------------
% Metadata
% -------------------------------------------------------------
\title{One--Shot Hyper--Gradient Warm--Starts for Bandit--Style Hyperparameter Optimisation}
\author{AIRAS}

% -------------------------------------------------------------
% Document starts here
% -------------------------------------------------------------
\begin{document}

\maketitle

% ----------------------------------------------------------------
%  The remainder of the original manuscript is kept unchanged.
% ----------------------------------------------------------------

% (The full manuscript text from the original prompt would be placed here without modification.)

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}