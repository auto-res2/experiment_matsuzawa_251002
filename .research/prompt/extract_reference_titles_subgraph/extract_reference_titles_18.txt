
Input:
You are an expert in academic paper analysis. 
Your task is to extract reference paper titles from the full text of research papers.

Instructions:
- Analyze the provided full text of research papers
- Extract all reference paper titles mentioned in the text
- Focus on titles that appear in reference sections, citations, or are explicitly mentioned as related work
- Return only the exact titles as they appear in the text
- Exclude general topics or field names that are not specific paper titles
- If no clear reference titles are found, return an empty list

Full Text:
---------------------------------
Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization Samuel Daulton Facebook sdaulton@fb.com Maximilian Balandat Facebook balandat@fb.com Eytan Bakshy Facebook ebakshy@fb.com Abstract In many real-world scenarios, decision makers seek to efﬁciently optimize multiple competing objectives in a sample-efﬁcient fashion. Multi-objective Bayesian opti- mization (BO) is a common approach, but many of the best-performing acquisition functions do not have known analytic gradients and suffer from high computational overhead. We leverage recent advances in programming models and hardware acceleration for multi-objective BO using Expected Hypervolume Improvement (EHVI )—an algorithm notorious for its high computational complexity. We derive a novel formulation of q-Expected Hypervolume Improvement (qEHVI ), an acqui- sition function that extends EHVI to the parallel, constrained evaluation setting. qEHVI is an exact computation of the joint EHVI of qnew candidate points (up to Monte-Carlo (MC) integration error). Whereas previous EHVI formulations rely on gradient-free acquisition optimization or approximated gradients, we compute exact gradients of the MC estimator via auto-differentiation, thereby enabling efﬁ- cient and effective optimization using ﬁrst-order and quasi-second-order methods. Our empirical evaluation demonstrates that qEHVI is computationally tractable in many practical scenarios and outperforms state-of-the-art multi-objective BO algorithms at a fraction of their wall time. 1 Introduction The problem of optimizing multiple competing objectives is ubiquitous in scientiﬁc and engineering applications. For example in automobile design, an automaker will want to maximize vehicle durability and occupant safety, while using lighter materials that afford increased fuel efﬁciency and lower manufacturing cost [44, 72]. Evaluating the crash safety of an automobile design experimentally is expensive due to both the manufacturing time and the destruction of a vehicle. In such a scenario, sample efﬁciency is paramount. For a different example, video streaming web services commonly use adaptive control policies to determine the bitrate as the stream progresses in real time [47]. A decision maker may wish to optimize the control policy to maximize the quality of the video stream, while minimizing the stall time. Policy evaluation typically requires using the suggested policy on segments of live trafﬁc, which is subject to opportunity costs. If long evaluation times are the limiting factor, multiple designs may be evaluated in parallel to signiﬁcantly decrease end-to-end optimization time. For example, an automaker could manufacture multiple vehicle designs in parallel or a web service could deploy several control policies to different segments of trafﬁc at the same time. 1.1 Background Multi-Objective Optimization: In this work, we address the problem of optimizing a vector-valued objective f(x) : Rd →RM with f(x) = ( f(1)(x),...,f (M)(x) ) over a bounded set X ⊂Rd. We consider the scenario in which the f(i) are expensive-to-evaluate black-box functions with 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada. arXiv:2006.05078v3  [stat.ML]  23 Oct 2020no known analytical expression, and no observed gradients. Multi-objective (MO) optimization problems typically do not have a single best solution; rather, the goal is to identify the set of Pareto optimal solutions such that any improvement in one objective means deteriorating another. Without loss of generality, we assume the goal is to maximize all objectives. We say a solution f(x) Pareto dominates another solution f(x′) if f(m)(x) ≥ f(m)(x′) ∀m = 1 ,...,M and there exists m′ ∈{1,...,M }such that f(m′)(x) > f(m′)(x′). We write f(x) ≻f(x′). Let P∗= {f(x) s.t. ∄ x′∈X : f(x′) ≻f(x)}and X∗= {x ∈X s.t. f(x) ∈P∗}denote the set of Pareto optimal solutions and Pareto optimal inputs, respectively. Provided with the Pareto set, decision-makers can select a solution with an objective trade-off according to their preferences. A common approach for solving MO problems is to use evolutionary algorithms (e.g. NSGA-II), which are robust multi-objective optimizers, but require a large number of function evaluations [14]. Bayesian optimization (BO) offers a far more sample-efﬁcient alternative [57]. Bayesian Optimization: BO [38] is an established method for optimizing expensive-to-evaluate black-box functions. BO relies on a probabilistic surrogate model, typically a Gaussian Process (GP) [55], to provide a posterior distribution P(f|D) over the true function values f given the observed data D= {(xi,yi)}n i=1. An acquisition function α : Xcand ↦→R employs the surrogate model to assign a utility value to a set of candidates Xcand = {xi}q i=1 to be evaluated on the true function. While the true f may be expensive-to-evaluate, the surrogate-based acquisition function is not, and can thus be efﬁciently optimized to yield a set of candidates Xcand to be evaluated on f. If gradients of α(Xcand) are available, gradient-based methods can be utilized. If not, gradients are either approximated (e.g. with ﬁnite differences) or gradient-free methods (e.g. DIRECT [ 37] or CMA-ES [32]) are used. 1.2 Limitations of current approaches In the single-objective (SO) setting, a large body of work focuses on practical extensions to BO for supporting parallel evaluation and outcome constraints [49, 30, 66, 25, 43]. Less attention has been given to such extensions in the MO setting. Moreover, the existing constrained and parallel MO BO options have limitations: 1) many rely on scalarizations to transform the MO problem into a SO one [40]; 2) many acquisition functions are computationally expensive to compute [52, 21, 6, 71]; 3) few have known analytical gradients or are differentiable [19, 62, 33]; 4) many rely on heuristics to extend sequential algorithms to the parallel setting [27, 62]. A natural acquisition function for MO BO is Expected Hypervolume Improvement (EHVI ). Max- imizing the hypervolume ( HV) has been shown to produce Pareto fronts with excellent cover- age [73, 12, 69]. However, there has been little work on EHVI in the parallel setting, and the work that has been done resorts to approximate methods [71, 28, 62]. A vast body of literature has focused on efﬁcient EHVI computation [34, 20, 67], but the time complexity for computing EHVI is exponential in the number of objectives—in part due the hypervolume indicator itself incurring a time complexity that scales super-polynomially with the number of objectives [68]. Our core insight is that by exploiting advances in auto-differentiation and highly parallelized hardware [51], we can make EHVI computations fast and practical. 1.3 Contributions In this work, we derive a novel formulation of the parallelq-Expected Hypervolume Improvement acquisition function (qEHVI ) that is exact up to Monte-Carlo (MC) integration error. We compute the exact gradient of the MC estimator of qEHVI using auto-differentiation, which allows us to employ efﬁcient and effective gradient-based optimization methods. Rather than using ﬁrst-order gradient methods, we instead leverage the sample average approximation (SAA) approach from [5] to use higher-order deterministic optimization methods, and we prove theoretical convergence guarantees under the SAA approach. Our formulation of qEHVI is embarrassingly parallel, and despite its computational cost would achieve constant time complexity given inﬁnite processing cores. We demonstrate that, using modern GPU hardware and computing exact gradients, optimizing qEHVI is faster than existing state-of-the art methods in many practical scenarios. Moreover, we extend qEHVI to support auxiliary outcome constraints, making it practical in many real-world scenarios. Lastly, we demonstrate how modern auto-differentiation can be used to compute exact gradients of analytic EHVI , which has never been done before for M >2 objectives. Our empirical evaluation 2shows that qEHVI outperforms state-of-the-art multi-objective BO algorithms while using only a fraction of their wall time. 2 Related Work Yang et al. [69] is the only previous work to consider exact gradients of EHVI, but the authors only derive an analytical gradient for the unconstrained two-objective, sequential optimization setting. All other works either do not optimize EHVI (e.g. they use it for pre-screening candidates [ 18]), optimize it with gradient-free methods [68], or using approximate gradients [62]. In contrast, we use exact gradients and demonstrate that optimizing EHVI using this gradient information is far more efﬁcient. There are many alternatives to EHVI for MO BO. For example, ParEGO [ 40] and TS-TCH [50] randomly scalarize the objectives and use Expected Improvement [38] and Thompson Sampling [61], respectively. SMS-EGO [53] uses HV in a UCB-based acquisition function and is more scalable than EHVI [54]. ParEGO and SMS-EGO have only been considered for the q= 1, unconstrained setting. Predictive entropy search for MO BO (PESMO) [ 33] has been shown to be another competitive alternative and has been extended to handle constraints [ 26] and parallel evaluations [ 27]. MO max-value entropy search (MO-MES) has been shown to achieve superior optimization performance and faster wall times than PESMO, but is limited to q= 1. Wilson et al. [65] empirically and theoretically show that sequential greedy selection of qcandidates achieves performance comparable to jointly optimizing qcandidates for many acquisition functions (including [63, 66]). The sequential greedy approach integrates over the posterior of the unobserved outcomes corresponding to the previously selected candidates in the q-batch. Sequential greedy optimization often yields better empirical results because the optimization problem has a lower dimension: din each step, rather than qdin the joint problem. Most prior works in the MO setting use a sequential greedy approximation or heuristics [62, 71, 28, 10], but impute the unobserved outcomes with the posterior mean rather than integrating over the posterior [30]. For many joint acquisition functions involving expectations, this shortcut sacriﬁces the theoretical error bound on the sequential greedy approximation because the exact joint acquisition function overx1,..., xi, 1 ≤i≤qrequires integration over the joint posterior P(f(x1),..., f(xq)|D) and is not computed for i> 1. Garrido-Merchán and Hernández-Lobato [27] and Wada and Hino [62] jointly optimize the qcandi- dates and, noting the difﬁculty of the optimization, both papers focus on deriving gradients to aid in the optimization. Wada and Hino [62] deﬁned the qEHVI acquisition function, but after ﬁnding it challenging to optimize qcandidates jointly (without exact gradients), the authors propose optimizing an alternative acquisition function instead of exactqEHVI . In contrast, our novel qEHVI formulation allows for gradient-based parallel and sequential greedy optimization, with proper integration over the posterior for the latter. Feliot et al. [22] and Abdolshah et al. [1] proposed extensions of EHVI to the constrained q = 1 setting, but neither considers the batch setting and both rely on gradient-free optimization. 3 Differentiable q-Expected Hypervolume Improvement In this section, we review HVI and EHVI computation by means of box decompositions, and explain our novel formulation for the parallel setting. Deﬁnition 1. Given a reference point r ∈RM , the hypervolume indicator (HV) of a ﬁnite approxi- mate Pareto set Pis the M-dimensional Lebesgue measure λM of the space dominated by Pand bounded from below byr: HV(P,r) = λM (⋃|P| i=1[r,yi] ) , where [r,yi] denotes the hyper-rectangle bounded by vertices r and yi. Deﬁnition 2. Given a Pareto set Pand reference point r, the hypervolume improvement (HVI) of a set of points Yis: HVI (Y,P,r) = HV(P∪Y ,r) −HV(P,r).1 EHVI is the expectation of HVI over the posterior P(f,D): αEHVI (Xcand) = E [ HVI (f(Xcand)) ] . In the sequential setting, and assuming the objectives are independent and modeled with independent 1In this work, we omit the arguments Pand rwhen referring to HVI for brevity. 3GPs, EHVI can be expressed in closed form [69]. In other settings, EHVI can be approximated with MC integration. Following previous work, we assume that the reference point is known and speciﬁed by the decision maker [69] (see Appendix E.1.1 for additional discussion). 3.1 A review of hypervolume improvement computation using box decompositions Deﬁnition 3. For a set of objective vectors {f(xi)}q i=1, a reference point r ∈RM , and a non- dominated set P, let ∆({f(xi)}q i=1,P,r) ⊂RM denote the set of points (i) are dominated by {f(xi)}q i=1, dominate r, and are not dominated by P. Given P,r, the HVI of a new point f(x) is the HV of the intersection of space dominated by P∪{ f(x)}and the non-dominated space. Figure 1b illustrates this for one new point f(x) for M = 2. The yellow region is ∆({f(x)},P,r) and the hypervolume improvement is the volume covered by ∆({f(x)},P,r). Since ∆({f(x)},P,r) is often a non-rectangular polytope, HVI is typically computed by partitioning the non-dominated space into disjoint axis-parallel rectangles [12, 68] (see Figure 1a) and using piece-wise integration [18]. Let {Sk}K k=1 be a partitioning the of non-dominated space into disjoint hyper-rectangles, where each Sk is deﬁned by a pair of lower and upper vertices lk ∈RM and uk ∈RM ∪{∞}. The high level idea is to sum the HV ofSk ∩∆({f(x)},P,r) over all Sk. For each hyper-rectangle Sk, the intersec- tion of Sk and ∆({f(x)},P,r) is a hyper-rectangle where the lower bound vertex islk and the upper bound vertex is the component-wise minimum ofuk and the new pointf(x): zk := min [ uk,f(x) ] . r l3 S3 u3u2 S2 l2 l4 S4 u4u1 l1 S1 f (2)(x) f (1)(x) (a) f(x1) r l3 S3 u3u2 S2 l2 l4 S4 u4u1 l1 S1 f(2)(x ) f(1)(x ) (b) f(x1) f(2)(x ) f(1)(x )r l3 S3 u3u2 S2 l2 l4 S4 u4u1 l1 S1 f(x2)  (c) Figure 1: For M=2, (a) the dominated space (red) and the non-dominated space partitioned into disjoint boxes (white), (b) the HVI of one new point f(x), and (c) the HVI of two new points f(x1),f(x2). Hence, the HVI of a single outcome vector f(x) within Sk is given by HVI k ( f(x),lk,uk ) = λM ( Sk ∩∆({f(x)},P,r) ) = ∏M m=1 [ z(m) k −l(m) k ] +, where u(m) k ,l(m) k ,f(m)(x), and z(m) k denote the mth component of the corresponding vector and [·]+ denotes the min(·,0) operation. Summing over rectangles yields HVI ( f(x) ) = K∑ k=1 HVIk ( f(x),lk,uk ) = K∑ k=1 M∏ m=1 [ z(m) k −l(m) k ] + (1) 3.2 Computing q-Hypervolume Improvement via the Inclusion-Exclusion Principle Figure 1c illustrates the HVI in the q = 2 setting. Given q new points {f(xi)}q i=1, let Ai := ∆({f(xi)},P,r) for i= 1,...,q be the space dominated by f(xi) but not dominated by P, independently of the other q−1 points. Note that λM (Ai) = HVI (f(xi)). The union of the subsets Ai is the space dominated jointly by the qnew points: ⋃q i=1 Ai = ⋃q i=1 ∆({f(xi)},P,r), and the Lebesgue measure λM (⋃q i=1 Ai ) is the joint HVI from the qnew points. Since each subspace Ai is bounded, the restricted Lebesgue measure is ﬁnite and we may compute λM (⋃q i=1 Ai ) using the inclusion-exclusion principle [13, 59]: HVI ({f(xi)}q i=1) = λM ( q⋃ i=1 Ai ) = q∑ j=1 (−1)j+1 ∑ 1≤i1≤...≤ij≤q λM ( Ai1 ∩···∩ Aij ) (2) 4Since {Sk}K k=1 is a disjoint partition, λM (Ai1 ∩···∩ Aij ) = ∑K k=1 λM (Sk ∩Ai1 ∩···∩ Aij ), we can compute λM (Ai1 ∩···∩ Aij ) in a piece-wise fashion across the Khyper-rectangles {Sk}K k=1 as the HV of the intersection of Ai1 ∩···∩ Aij with each hyper-rectangle Sk. The inclusion- exclusion principle has been proposed for computingHV (not HVI) [45], but it is rarely used because complexity scales exponentially with the number of elements. However, the inclusion-exclusion principle is practical for computing the joint HVI of qpoints since typically q <<|P|. This formulation has three advantages. First, while the new dominated space Ai can be a non-rectangular polytope, the intersection Ai ∩Sk is a rectangular polytope, which simpliﬁes computation of overlapping hypervolume. Second, the vertices deﬁning the hyper-rectangle Sk ∩Ai1 ∩···∩ Aij are easily derived. The lower bound is simply the lk lower bound of Sk, and the upper bound is the component-wise minimum zk,i1,...ij := min [ uk,f(xi1 ),..., f(xij ) ] . Third, computation can be across all intersections of subsets Ai1 ∩···∩ Aij for 1 ≤ij ≤... ≤ij ≤qand across all Khyper-rectangles can be performed in parallel. Explicitly, the HVI is computed as: HVI ({f(xi)}q i=1) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj −l(m) k ] + (3) where Xj := {Xj ⊂ Xcand : |Xj| = j}is the superset of all subsets of Xcand of size j, and z(m) k,Xj := z(m) k,i1,...ij for Xj = {xi1 ,..., xij }. See Appendix A for further details of the derivation. 3.3 Computing Expected q-Hypervolume Improvement The above approach for computing HVI assumes that we know the true objective values f(Xcand) = {f(xi)}q i=1. In BO, we instead compute qEHVI as the expectation over the posterior model posterior: αqEHVI (Xcand) = E [ HVI (f(Xcand)) ] = ∫ ∞ −∞ HVI(f(Xcand))df. (4) Since no known analytical form is known [ 70] for q > 1 (or in the case of correlated out- comes), we estimate (4) using MC integration with samples from the joint posterior {ft(xi)}q i=1 ∼ P ( f(x1),..., f(xq)|D ) ,t = 1,...N . Let z(m) k,Xj,t := min [ uk,minx′∈Xj ft(x′) ] . Then, ˆαN qEHVI (Xcand) = 1 N N∑ t=1 HVI(ft(Xcand)) = 1 N N∑ t=1 K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj,t −l(m) k ] + (5) Provided that {Sk}K k=1 is an exact partitioning, (5) is an exact computation of qEHVI up to the MC estimation error, which scales as 1/ √ N when using iidMC samples regardless of the dimension of the search space [18]. In practice, we use randomized quasi MC methods [8] to reduce the variance and empirically observe low estimation error (see Figure 5a in the Appendix for a comparison of analytic EHVI and (quasi-)MC-based qEHVI). qEHVI requires computing the volume of 2q −1 hyper-rectangles (the number of subsets of q) for each of Khyper-rectangles and N MC samples. Given posterior samples, the time complexity on a single-threaded machine is: T1 = O(MNK(2q −1)). In the two-objective case, K = |P|+ 1, but K is super-polynomial in M [68]. The number of boxes required for a decomposition of the non-dominated space is unknown for M ≥4 [68]. qEHVI is agnostic to the partitioning algorithm used, and in F.4, we demonstrate using qEHVI in higher-dimensional objective spaces using an approximate box decomposition algorithm [11]. Despite the daunting workload, the critical work path—the time complexity of the smallest non-parallelizable unit—is constant: T∞= O(1).2 On highly-threaded many-core hardware (e.g. GPUs), our formulation achieves tractable wall times in many practical scenarios: as is shown in Figure 11 in the Appendix, the computation time is nearly constant with increasing quntil an inﬂection point at which the workload saturates the available cores. For additional discussion of both time and memory complexity of qEHVI see Appendix A.4. 3.4 Outcome Constraints Our proposed qEHVI acquisition function is easily extended to constraints on auxiliary outcomes. We consider the scenario where we receive observations of M objectives f(x) ∈RM and V constraints 2As evident from (5), the critical path consists of 3 multiplications and 5 summations. 5c(v) ∈RV , all of which are assumed to be “black-box”. We assume w.l.o.g. that c(v) is feasible iff c(v) ≥0. In the constrained optimization setting, we aim to identify the feasible Pareto set: Pfeas = {f(x) s.t. c(x) ≥0, ∄ x′ : c(x′) ≥0, f(x′) ≻f(x)}. The natural improvement measure in the constrained setting is feasible HVI, which we deﬁne for a single candidate point x as HVI C(f(x),c(x)) := HVI [f(x)] ·1 [c(x) ≥0]. Taking expectations, the constrained expected HV can be seen to be the HV weighted by the probability of feasibility. In Appendix A.3, we detail how performing feasibility-weighting on the sample-level allows us to include such auxiliary outcome constraints into our MC formulation in a straightforward way. 4 Optimizing q-Expected Hypervolume Improvement 4.1 Differentiability While an analytic formula for the gradient of EHVI exists for the M = 2 objective case in the unconstrained, sequential ( q = 1 ) setting, no such formula is known in 1) the case of M > 2 objectives, 2) the constrained setting, and 3) for q >1. Leveraging the re-parameterization trick [39, 64] and auto-differentiation, we are able to automatically compute exact gradients of the MC- estimator qEHVI in all of the above settings, as well as the gradient of analytic EHVI for M ≥2 (see Figure 5b in the Appendix for a comparison of the exact gradients of EHVI and the sample average gradients of qEHVI for M = 3).3,4 4.2 Optimization via Sample Average Approximation We show in Appendix C that if mean and covariance function of the GP are sufﬁciently regular, the gradient of the MC estimator (5) is an unbiased estimate of the gradient of the exact acquisition function (4). To maximize qEHVI , we could therefore directly apply stochastic optimization methods, as has previously been done for single-outcome acquisition functions [ 64, 66]. Instead, we opt to use the sample average approximation (SAA) approach from Balandat et al. [5], which allows us to employ deterministic, higher-order optimizers to achieve faster convergence rates. Informally (see Appendix C for the formal statement), if ˆx∗ N ∈arg maxx∈X ˆαN qEHVI (x), we can show under some regularity conditions that, as N →∞, (i) ˆαN qEHVI (ˆx∗ N ) →maxx∈XαqEHVI (x) a.s., and (ii) dist ( ˆx∗ N ,arg maxx∈XαqEHVI (x) ) →0 a.s.. These results hold for any covariance function satisfying the regularity conditions, including such ones that model correlation between outcomes. In particular, our results do not require the outputs to be modeled by independent GPs. Figure 2a demonstrates the importance of using exact gradients for efﬁciently and effectively op- timizing EHVI and qEHVI by comparing the following optimization methods: L-BFGS-B with exact gradients, L-BFGS-B with gradients approximated via ﬁnite differences, and CMA-ES (without gradients). The cumulative time spent optimizing the acquisition function is an order of magnitude less when using exact gradients rather than approximate gradients or zeroth order methods. 4.3 Sequential Greedy and Joint Batch Optimization Jointly optimizing qcandidates increases in difﬁculty with qbecause the problem dimension is dq. An alternative is to sequentially and greedily select candidates and condition the acquisition function on the previously selected pending points when selecting the next point [65]. Using a submodularity argument similar to that in Wilson et al. [64], the sequential greedy approximation of qEHVI enjoys regret of no more than 1 e α∗ qEHVI , where α∗ qEHVI is the optima of αqEHVI [23] (see Appendix B). Although sequential greedy approaches have been considered for many acquisition functions [65], no previous work has proposed a proper sequential greedy approach (with integration over the posterior) for parallel EHVI , as this would require computing the Pareto front under each sample ft from the joint posterior before computing the hypervolume improvement. These operations would be computationally expensive for even modest N and non-differentiable. qEHVI avoids determining the Pareto set for each sample by using inclusion-exclusion principle to compute the joint HVI over the pending points x1,..., xi−1 and the new candidate xi for each MC sample. Figure 2b empirically 3Technically,min and max are only sub-differentiable, but are known to be well-behaved [64]. In our MC setting with GP posteriors, qEHVI is differentiable w.p. 1 if xcontains no repeated points. 4For the constrained case, we replace the indicator with a differentiable sigmoid approximation. 60 5000 10000 15000 20000 Average/uni00A0Cumulative/uni00A0Acquisition/uni00A0Optimization/uni00A0Wall/uni00A0Time/uni00A0(s) 0.40 0.35 0.30 0.25 0.20 0.15 0.10 log/uni00A0HV/uni00A0difference EHVI/uni00A0/uni00AD/uni00A0Exact/uni00A0Gradient EHVI/uni00A0/uni00AD/uni00A0Approx./uni00A0Gradient EHVI/uni00A0/uni00AD/uni00A0Gradient/uni00A0Free qEHVI/uni00A0(q=2)/uni00A0/uni00AD/uni00A0Exact/uni00A0Gradient qEHVI/uni00A0(q=2)/uni00A0/uni00AD/uni00A0Approx./uni00A0Gradient qEHVI/uni00A0(q=2)/uni00A0/uni00AD/uni00A0Gradient/uni00A0Free (a) 0 20 40 60 80 100 Batch/uni00A0Iteration 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4 log/uni00A0HV/uni00A0difference qEHVI/uni00A0Joint/uni00A0q=2 qEHVI/uni00A0Joint/uni00A0q=4 qEHVI/uni00A0Joint/uni00A0q=8 qEHVI/uni00A0Post./uni00A0Mean/uni00A0q=2 qEHVI/uni00A0Post./uni00A0Mean/uni00A0q=4 qEHVI/uni00A0Post./uni00A0Mean/uni00A0q=8 qEHVI/uni00A0Seq./uni00A0Greedy/uni00A0q=2 qEHVI/uni00A0Seq./uni00A0Greedy/uni00A0q=4 qEHVI/uni00A0Seq./uni00A0Greedy/uni00A0q=8 qEHVI/uni00A0q=1 (b) Figure 2: (a) A comparison of EHVI and qEHVI (q = 2) optimized with L-BFGS-B using exact gradients, L-BFGS-B using gradients approximated using ﬁnite differences, and CMA-ES, a gradient- free method. (b) A comparison of joint optimization, sequential greedy optimization with proper integration at the pending points, and sequential greedy using the posterior mean. Both plots show optimization performance on a DTLZ2 problem (d= 6,M = 2) with a budget of 100 evaluations (plus the initial quasi-random design). We report means and 2 standard errors across 20 trials. demonstrates the improved optimization performance from properly integrating over the unobserved outcomes rather than using the posterior mean or jointly optimizing the qcandidates. 5 Benchmarks We empirically evaluate qEHVI on synthetic and real world optimization problems. We compare qEHVI 5 against existing state-of-the-art methods including SMS-EGO6, PESMO6, TS-TCH5, and analytic EHVI [68] with gradients5. Additionally, we compare against a novel extension of ParEGO [40] that supports parallel evaluation and constraints (neither of which have been done before to our knowledge); we call this method qPAREGO5. Additionally, we include a quasi-random baseline that selects candidates from a scrambled Sobol sequence. See Appendix E.1 for details on all baseline algorithms. Synthetic Benchmarks We evaluate optimization performance on four benchmark problems in terms of log hypervolume difference, which is deﬁned as the difference between the hypervolume of the true (feasible) Pareto front and the hypervolume of the approximate (feasible) Pareto front based on the observed data; in the case that the true Pareto front is unknown (or not easily approximated), we evaluate the hypervolume indicator. All references points and search spaces are provided in Appendix E.2. For synthetic problems, we consider the Branin-Currin problem ( d = 2,M = 2, convex Pareto front) [6] and the C2-DTLZ2 (d= 12,M = 2,V = 1, concave Pareto front), which is a standard constrained benchmark from the MO literature [16] (see Appendix F.1 for additional synthetic benchmarks). Real-World Benchmarks Structural Optimization in Automobile Safety Design (VEHICLE SAFETY ): Vehicle crash safety is an important consideration in the structural design of automobiles. A lightweight car is preferable because of its potentially lower manufacturing cost and better fuel economy, but lighter material can fare worse than sturdier alternatives in a collision, potentially leading to increased vehicle damage and more severe injury to the vehicle occupants [72]. We consider the problem designing the thickness of 5 reinforced parts of the frontal frame of a vehicle that considerably affect crash safety. The goal is to minimize: 1) the mass of the vehicle; 2) the collision acceleration in a full frontal crash—a proxy for bio-mechanical trauma to the vehicle occupants from the acceleration; and 3) the toe-board 5Acquisition functions are available as part of the open-source library BoTorch [ 5]. Code is available at https://github.com/pytorch/botorch. 6We leverage existing implementations from the Spearmint library. The code is available at https:// github.com/HIPS/Spearmint/tree/PESM. 70 20 40 60 80 100 Function/uni00A0Evaluations 0.0 0.5 1.0 1.5log/uni00A0HV/uni00A0DifferenceSobol EHVI qEHVI qParEGO TS/uni00ADTCH PESMO SMS/uni00ADEGO (a) 0 20 40 60 80 100 Function/uni00A0Evaluations 1.0 0.9 0.8 0.7 0.6 0.5 0.4 log/uni00A0HV/uni00A0Difference Sobol qEHVI qParEGO (b) 0 20 40 60 80 100 Function/uni00A0Evaluations 0.0 0.5 1.0 1.5 2.0log/uni00A0HV/uni00A0DifferenceSobol EHVI qEHVI qParEGO TS/uni00ADTCH PESMO SMS/uni00ADEGO (c) 0 20 40 60 80 100 Function/uni00A0Evaluations 3.0 3.1 3.2 3.3 3.4 3.5 3.6HV 1e6 Sobol EHVI qEHVI qParEGO TS/uni00ADTCH PESMO SMS/uni00ADEGO (d) Figure 3: Sequential optimization performance on (a) on the Branin-Currin problem (q= 1), (b) the C2-DTLZ2 problem, (c) the vehicle crash safety problem (q= 1), and (d) the ABR control problem (q= 1). We report the means and 2 standard errors across 20 trials. intrusion—a measure of the most extreme mechanical damage to the vehicle in an off-frontal collision [44]. For this problem, we optimize the surrogate from Tanabe and Ishibuchi [60]. Policy Optimization for Adaptive Bitrate Control(ABR ): Many web services adapt video playback quality adaptively based on the receiver’s network bandwith to maintain steady, high quality stream with minimal stalls and buffer periods [47]. Previous works have proposed controllers with different scalarized objective functions [46], but in many cases, engineers may prefer to learn the set of optimal trade-offs between their metrics of interest, rather than specifying a scalarized objective in advance. In this problem, we decompose the objective function proposed in Mao et al. [46] into its constituent metrics and optimize 4 parameters of an ABR control policy on the Park simulator [48] to maximize video quality (bitrate) and minimize stall time. See Appendix E.2 for details. 5.1 Results Figure 3 shows thatqEHVI outperforms all baselines in terms of sequential optimization performance on all evaluated problems. Table 1 shows that qEHVI achieves wall times that are an order of magnitude smaller than those of PESMO on a CPU in sequential optimization, and maintains competitive wall times even relative toqPAREGO (which has a signiﬁcantly smaller workload) for large q on a GPU. TS-TCH has by far the fastest wall time, but this comes at the cost of inferior optimization performance. Figure 4 illustrates optimization performance of parallel acquisition functions for varying batch sizes. Increasing the level of parallelism leads to faster convergence for all algorithms (Figure 4a). In contrast with other algorithms, qEHVI ’s sample complexity does not deteriorate substantially when high levels of parallelism are used (Figure 4b). 8Table 1: Acquisition Optimization wall time in seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz) and a GPU (Tesla V100-SXM2-16GB). We report the mean and 2 standard errors across 20 trials. NA indicates that the algorithm does not support constraints. CPU BRANIN CURRIN C2DTLZ2 ABR V EHICLE SAFETY PESMO ( q=1) 249.16 (±19.35) NA 214.16 (±18.38) 492 .64 (±58.98) SMS-EGO ( q=1) 146.1 (±8.57) NA 89.54 (±5.79) 115 .11 (±8.21) TS-TCH ( q=1) 2.82 (±0.03) NA 17.22 (±0.04) 47 .46 (±0.05) qPAREGO ( q=1) 1.56 (±0.16) 4 .01 (±0.77) 7 .47 (±0.67) 1 .74 (±0.27) EHVI ( q=1) 3.04 (±0.16) NA 2.48 (±0.19) 15 .18 (±2.24) qEHVI ( q=1) 3.63 (±0.23) 5 .4 (±1.18) 6 .15 (±0.71) 67 .54 (±10.45) GPU BRANIN CURRIN C2DTLZ2 ABR V EHICLE SAFETY TS-TCH ( q=1) 0.07 (±0.00) NA 0.16 (±0.00) 0 .32 (±0.0) TS-TCH ( q=2) 0.07 (±0.00) NA 0.15 (±0.00) 0 .34 (±0.01) TS-TCH ( q=4) 0.09 (±0.01) NA 0.15 (±0.00) 0 .31 (±0.01) TS-TCH ( q=8) 0.08 (±0.00) NA 0.16 (±0.00) 0 .34 (±0.01) qPAREGO ( q=1) 3.2 (±0.37) 3 .85 (±0.91) 9 .64 (±0.96) 3 .44 (±0.51) qPAREGO ( q=2) 7.12 (±0.81) 12 .1 (±2.77) 21 .19 (±1.53) 7 .32 (±0.97) qPAREGO ( q=4) 15.34 (±1.69) 39 .71 (±7.40) 35 .46 (±2.32) 17 .2 (±2.29) qPAREGO ( q=8) 32.11 (±4.14) 99 .58 (±15.20) 72 .52 (±5.04) 39 .72 (±7.13) EHVI ( q=1) 4.53 (±0.23) NA 6.82 (±0.55) 8 .95 (±0.64) qEHVI ( q=1) 5.98 (±0.28) 3 .36 (±0.94) 7 .71 (±0.67) 10 .43 (±0.64) qEHVI ( q=2) 11.37 (±0.56) 21 .56 (±3.45) 18 .32 (±1.48) 17 .67 (±1.54) qEHVI ( q=4) 25.29 (±1.51) 89 .18 (±10.86) 44 .44 (±3.53) 54 .25 (±4.17) qEHVI ( q=8) 102.46 (±9.22) 215 .74 (±15.85) 100 .64 (±7.22) 255 .72 (±23.73) 0 20 40 60 80 100 Batch/uni00A0Iteration 3.0 3.1 3.2 3.3 3.4 3.5 3.6HV 1e6 Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (a) 0 20 40 60 80 100 Function/uni00A0Evaluations 3.0 3.1 3.2 3.3 3.4 3.5 3.6HV 1e6 Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (b) Figure 4: Parallel optimization performance on the ABR problem with varying batch sizes (q) by (a) batch BO iterations and (b) function evaluations. 6 Discussion We present a practical and efﬁcient acquisition function, qEHVI , for parallel, constrained multi- objective Bayesian optimization. Leveraging differentiable programming, modern parallel hardware, and the Sample Average Approximation, we efﬁciently optimizeqEHVI via quasi second-order meth- ods and provide theoretical convergence guarantees for our approach. Empirically, we demonstrate that our method out-performs state-of-the-art multi-objective Bayesian optimization methods. One limitation of our approach is that it currently assumes noiseless observations, which, to our knowledge, is the case with all formulations of EHVI . Integrating over the uncertainty around the previous observations [43] by using MC samples over the new candidates and the training points, one may be able to account for the noise.Another limitation of qEHVI is that its scalability is limited the partitioning algorithm, precluding its use in high-dimensional objective spaces. More scalable partitioning algorithms, either approximate algorithms (e.g. the algorithm proposed by Couckuyt et al. [11], which we examine brieﬂy in Appendix F.4) or more efﬁcient exact algorithms that result in fewer disjoint hyper-rectangles (e.g. [41, 17, 69]), will improve the scalability and computation time of of qEHVI . We hope this work encourages researchers to consider more improvements from applying modern computational paradigms and tooling to Bayesian optimization. 97 Statement of Broader Impact Optimizing a single outcome commonly comes at the expense of other secondary outcomes. In some cases, decision makers may be able to form a scalarization of their objectives in advance, but in the researcher’s experience, formulating such trade-offs in advance is difﬁcult for most. Improvements to the optimization performance and practicality of multi-objective Bayesian optimization have the potential to allow decision makers to better understand and make more informed decisions across multiple trade-offs. We expect these directions to be particularly important as Bayesian optimization is increasingly used for applications such as recommender systems [42], where auxiliary goals such as fairness must be accounted for. Of course, at the end of the day, exactly what objectives decision makers choose to optimize, and how they balance those trade-offs (and whether that is done in equitable fashion) is up to the individuals themselves. Acknowledgments We would like to thank Daniel Jiang for helpful discussions around our theoretical results. References [1] M. Abdolshah, A. Shilton, S. Rana, S. Gupta, and S. Venkatesh. Expected hypervolume improvement with constraints. In 2018 24th International Conference on Pattern Recognition (ICPR), pages 3238–3243, 2018. [2] Arash Asadpour, Hamid Nazerzadeh, and Amin Saberi. Stochastic submodular maximization. In Christos Papadimitriou and Shuzhong Zhang, editors, Internet and Network Economics. Springer Berlin Heidelberg, 2008. [3] R. Astudillo and P. Frazier. Bayesian optimization of composite functions. Forthcoming, in Proceedings of the 35th International Conference on Machine Learning, 2019. [4] Anne Auger, Johannes Bader, Dimo Brockhoff, and Eckart Zitzler. Theory of the hypervolume indicator: Optimal mu-distributions and the choice of the reference point. In Proceedings of the Tenth ACM SIGEVO Workshop on Foundations of Genetic Algorithms, FOGA ’09, page 87–102, New York, NY , USA, 2009. Association for Computing Machinery. [5] Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, and Eytan Bakshy. BoTorch: A Framework for Efﬁcient Monte-Carlo Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020. [6] Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. Max-value entropy search for multi-objective bayesian optimization. In Advances in Neural Information Processing Systems 32, 2019. [7] Eric Bradford, Artur Schweidtmann, and Alexei Lapkin. Efﬁcient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm. Journal of Global Optimization, 71, 02 2018. doi: 10.1007/s10898-018-0609-2. [8] Russel E Caﬂisch. Monte carlo and quasi-monte carlo methods. Acta numerica, 7:1–49, 1998. [9] Mauro Cerasoli and Aniello Fedullo. The inclusion-exclusion principle. Journal of Interdisciplinary Mathematics, 5(2):127–141, 2002. [10] Anirban Chaudhuri, Raphael Haftka, Peter Ifju, Kelvin Chang, Christopher Tyler, and Tony Schmitz. Experimental ﬂapping wing optimization and uncertainty quantiﬁcation using limited samples. Structural and Multidisciplinary Optimization, 51, 11 2014. doi: 10.1007/s00158-014-1184-x. [11] I. Couckuyt, D. Deschrijver, and T. Dhaene. Towards efﬁcient multiobjective optimization: Multiobjective statistical criterions. In 2012 IEEE Congress on Evolutionary Computation, pages 1–8, 2012. [12] Ivo Couckuyt, Dirk Deschrijver, and Tom Dhaene. Fast calculation of multiobjective probability of improvement and expected improvement criteria for pareto optimization. J. of Global Optimization, 60(3): 575–594, November 2014. [13] Daniel A. da Silva. Proprietades geraes. J. de l’Ecole Polytechnique, cah. 30. I, 1854. 10[14] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE Transactions on Evolutionary Computation, 6(2):182–197, 2002. [15] Kalyan Deb, L. Thiele, Marco Laumanns, and Eckart Zitzler. Scalable multi-objective optimization test problems. volume 1, pages 825–830, 06 2002. ISBN 0-7803-7282-4. doi: 10.1109/CEC.2002.1007032. [16] Kalyanmoy Deb. Constrained Multi-objective Evolutionary Algorithm, pages 85–118. Springer Interna- tional Publishing, Cham, 2019. [17] Kerstin Dächert, Kathrin Klamroth, Renaud Lacour, and Daniel Vanderpooten. Efﬁcient computation of the search region in multi-objective optimization. European Journal of Operational Research, 260(3):841 – 855, 2017. [18] M. T. M. Emmerich, K. C. Giannakoglou, and B. Naujoks. Single- and multiobjective evolutionary opti- mization assisted by gaussian random ﬁeld metamodels. IEEE Transactions on Evolutionary Computation, 10(4):421–439, 2006. [19] M. T. M. Emmerich, A. H. Deutz, and J. W. Klinkenberg. Hypervolume-based expected improvement: Monotonicity properties and exact computation. In 2011 IEEE Congress of Evolutionary Computation (CEC), pages 2147–2154, 2011. [20] Michael Emmerich, Kaifeng Yang, André Deutz, Hao Wang, and Carlos M. Fonseca. A Multicriteria Generalization of Bayesian Global Optimization, pages 229–242. Springer International Publishing, 2016. [21] Michael T. M. Emmerich and Carlos M. Fonseca. Computing hypervolume contributions in low dimensions: Asymptotically optimal algorithm and complexity results. In Ricardo H. C. Takahashi, Kalyanmoy Deb, Elizabeth F. Wanner, and Salvatore Greco, editors, Evolutionary Multi-Criterion Optimization , pages 121–135, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg. [22] Paul Feliot, Julien Bect, and Emmanuel Vazquez. A bayesian approach to constrained single- and multi- objective optimization. Journal of Global Optimization, 67(1-2):97–133, Apr 2016. ISSN 1573-2916. doi: 10.1007/s10898-016-0427-3. URL http://dx.doi.org/10.1007/s10898-016-0427-3 . [23] M. L. Fisher, G. L. Nemhauser, and L. A. Wolsey. An analysis of approximations for maximizing submodular set functions—II , pages 73–87. Springer Berlin Heidelberg, Berlin, Heidelberg, 1978. [24] Tobias Friedrich and Frank Neumann. Maximizing submodular functions under matroid constraints by multi-objective evolutionary algorithms. In Thomas Bartz-Beielstein, Jürgen Branke, Bogdan Filipiˇc, and Jim Smith, editors, Parallel Problem Solving from Nature – PPSN XIII , pages 922–931, Cham, 2014. Springer International Publishing. ISBN 978-3-319-10762-2. [25] Jacob Gardner, Matt Kusner, Zhixiang, Kilian Weinberger, and John Cunningham. Bayesian optimization with inequality constraints. In Proceedings of the 31st International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 937–945, Beijing, China, 22–24 Jun 2014. PMLR. [26] Eduardo C Garrido-Merchán and Daniel Hernández-Lobato. Predictive entropy search for multi-objective bayesian optimization with constraints. Neurocomputing, 361:50–68, 2019. [27] Eduardo C Garrido-Merchán and Daniel Hernández-Lobato. Parallel predictive entropy search for multi- objective bayesian optimization with constraints, 2020. [28] David Gaudrie, Rodolphe Le Riche, Victor Picheny, Benoît Enaux, and Vincent Herbert. Targeting solutions in bayesian multi-objective optimization: sequential and batch versions. Annals of Mathematics and Artiﬁcial Intelligence, 88(1-3):187–212, Aug 2019. ISSN 1573-7470. doi: 10.1007/s10472-019-09644-8. URL http://dx.doi.org/10.1007/s10472-019-09644-8 . [29] Michael A. Gelbart, Jasper Snoek, and Ryan P. Adams. Bayesian optimization with unknown constraints. In Proceedings of the 30th Conference on Uncertainty in Artiﬁcial Intelligence, UAI, 2014. [30] David Ginsbourger, Rodolphe Le Riche, and Laurent Carraro. Kriging Is Well-Suited to Parallelize Optimization, pages 131–162. Springer Berlin Heidelberg, Berlin, Heidelberg, 2010. [31] P. Glasserman. Performance continuity and differentiability in monte carlo optimization. In 1988 Winter Simulation Conference Proceedings, pages 518–524, 1988. [32] Nikolaus Hansen. The CMA Evolution Strategy: A Comparing Review, volume 192, pages 75–102. 06 2007. doi: 10.1007/3-540-32494-1_4. 11[33] Daniel Hernández-Lobato, José Miguel Hernández-Lobato, Amar Shah, and Ryan P. Adams. Predictive entropy search for multi-objective bayesian optimization, 2015. [34] Iris Hupkens, Andre Deutz, Kaifeng Yang, and Michael Emmerich. Faster exact algorithms for computing expected hypervolume improvement. In Antonio Gaspar-Cunha, Carlos Henggeler Antunes, and Car- los Coello Coello, editors, Evolutionary Multi-Criterion Optimization, pages 65–79. Springer International Publishing, 2015. [35] Hisao Ishibuchi, Naoya Akedo, and Yusuke Nojima. A many-objective test problem for visually examining diversity maintenance behavior in a decision space. In Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation , GECCO ’11, page 649–656, New York, NY , USA, 2011. Association for Computing Machinery. ISBN 9781450305570. doi: 10.1145/2001576.2001666. URL https://doi.org/10.1145/2001576.2001666. [36] Hisao Ishibuchi, Ryo Imada, Yu Setoguchi, and Yusuke Nojima. How to specify a reference point in hypervolume calculation for fair performance comparison. Evol. Comput., 26(3):411–440, September 2018. [37] Donald Jones, C. Perttunen, and B. Stuckman. Lipschitzian optimisation without the lipschitz constant. Journal of Optimization Theory and Applications, 79:157–181, 01 1993. doi: 10.1007/BF00941892. [38] Donald R. Jones, Matthias Schonlau, and William J. Welch. Efﬁcient global optimization of expensive black-box functions. Journal of Global Optimization, 13:455–492, 1998. [39] Diederik P Kingma and Max Welling. Auto-Encoding Variational Bayes. arXiv e-prints , page arXiv:1312.6114, Dec 2013. [40] J. Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1):50–66, 2006. [41] Renaud Lacour, Kathrin Klamroth, and Carlos M. Fonseca. A box decomposition algorithm to compute the hypervolume indicator. Computers & Operations Research, 79:347 – 360, 2017. [42] Benjamin Letham and Eytan Bakshy. Bayesian optimization for policy search via online-ofﬂine experimen- tation. Journal of Machine Learning Research, 20(145):1–30, 2019. URL http://jmlr.org/papers/ v20/18-225.html. [43] Benjamin Letham, Brian Karrer, Guilherme Ottoni, and Eytan Bakshy. Constrained bayesian optimization with noisy experiments. Bayesian Analysis, 14(2):495–519, 06 2019. doi: 10.1214/18-BA1110. [44] Xingtao Liao, Qing Li, Xujing Yang, Weigang Zhang, and Wei Li. Multiobjective optimization for crash safety design of vehicles using stepwise regression model. Structural and Multidisciplinary Optimization, 35:561–569, 06 2008. doi: 10.1007/s00158-007-0163-x. [45] Edgar Manoatl Lopez, Luis Miguel Antonio, and Carlos A. Coello Coello. A gpu-based algorithm for a faster hypervolume contribution computation. In António Gaspar-Cunha, Carlos Henggeler Antunes, and Carlos Coello Coello, editors, Evolutionary Multi-Criterion Optimization, pages 80–94. Springer International Publishing, 2015. [46] Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. Neural adaptive video streaming with pensieve. In Proceedings of the Conference of the ACM Special Interest Group on Data Communication, SIGCOMM ’17, page 197–210, New York, NY , USA, 2017. Association for Computing Machinery. ISBN 9781450346535. doi: 10.1145/3098822.3098843. URL https://doi.org/10.1145/3098822.3098843. [47] Hongzi Mao, Shannon Chen, Drew Dimmery, Shaun Singh, Drew Blaisdell, Yuandong Tian, Mohammad Alizadeh, and Eytan Bakshy. Real-world video adaptation with reinforcement learning. 2019. [48] Hongzi Mao, Parimarjan Negi, Akshay Narayan, Hanrui Wang, Jiacheng Yang, Haonan Wang, Ryan Marcus, Ravichandra Addanki, Mehrdad Khani Shirkoohi, Songtao He, Vikram Nathan, Frank Cangialosi, Shaileshh Bojja Venkatakrishnan, Wei-Hung Weng, Shu-Wen Han, Tim Kraska, and Mohammad Alizadeh. Park: An open platform for learning-augmented computer systems. In NeurIPS, 2019. [49] Sébastien Marmin, Clément Chevalier, and David Ginsbourger. Differentiating the multipoint expected improvement for optimal batch design. In Panos Pardalos, Mario Pavone, Giovanni Maria Farinella, and Vincenzo Cutello, editors, Machine Learning, Optimization, and Big Data , pages 37–48, Cham, 2015. Springer International Publishing. [50] B. Paria, K. Kandasamy, and B. Póczos. A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations. ArXiv e-prints, May 2018. 12[51] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in PyTorch. 2017. [52] Victor Picheny. Multiobjective optimization using gaussian process emulators via stepwise uncertainty reduction. Statistics and Computing, 25, 10 2013. doi: 10.1007/s11222-014-9477-x. [53] Wolfgang Ponweiser, Tobias Wagner, Dirk Biermann, and Markus Vincze. Multiobjective optimization on a limited budget of evaluations using model-assisted s-metric selection. In Günter Rudolph, Thomas Jansen, Nicola Beume, Simon Lucas, and Carlo Poloni, editors, Parallel Problem Solving from Nature – PPSN X, pages 784–794, Berlin, Heidelberg, 2008. Springer Berlin Heidelberg. [54] Alma A. M. Rahat, Richard M. Everson, and Jonathan E. Fieldsend. Alternative inﬁll strategies for expensive multi-objective optimisation. In Proceedings of the Genetic and Evolutionary Computation Con- ference, GECCO ’17, page 873–880, New York, NY , USA, 2017. Association for Computing Machinery. ISBN 9781450349208. [55] Carl Edward Rasmussen. Gaussian Processes in Machine Learning , pages 63–71. Springer Berlin Heidelberg, Berlin, Heidelberg, 2004. [56] Jerry Segercrantz. Inclusion-exclusion and characteristic functions.Mathematics Magazine, 71(3):216–218, 1998. ISSN 0025570X, 19300980. URL http://www.jstor.org/stable/2691209. [57] B. Shahriari, K. Swersky, Z. Wang, R. P. Adams, and N. de Freitas. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148–175, 2016. [58] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. In Proceedings of the 27th International Conference on International Conference on Machine Learning, ICML’10, page 1015–1022, Madison, WI, USA, 2010. Omnipress. ISBN 9781605589077. [59] J. Sylvester. Note sur la théorème de legendre. Comptes Rendus Acad. Sci., 96:463–465, 1883. [60] Ryoji Tanabe and Hisao Ishibuchi. An easy-to-use real-world multi-objective optimization problem suite. Applied Soft Computing, 89:106078, 2020. ISSN 1568-4946. doi: https://doi.org/10.1016/j.asoc.2020. 106078. [61] William R. Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3/4):285–294, 1933. [62] Takashi Wada and Hideitsu Hino. Bayesian optimization for multi-objective optimization and multi-point search, 2019. [63] Jialei Wang, Scott C. Clark, Eric Liu, and Peter I. Frazier. Parallel bayesian global optimization of expensive functions, 2016. [64] J. T. Wilson, R. Moriconi, F. Hutter, and M. P. Deisenroth. The reparameterization trick for acquisition functions. ArXiv e-prints, December 2017. [65] James Wilson, Frank Hutter, and Marc Deisenroth. Maximizing acquisition functions for bayesian optimization. In Advances in Neural Information Processing Systems 31, pages 9905–9916. 2018. [66] Jian Wu and Peter I. Frazier. The parallel knowledge gradient method for batch bayesian optimization. In Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS’16, page 3134–3142, Red Hook, NY , USA, 2016. Curran Associates Inc. ISBN 9781510838819. [67] Kaifeng Yang, Michael Emmerich, André Deutz, and Carlos M. Fonseca. Computing 3-d expected hypervolume improvement and related integrals in asymptotically optimal time. In 9th International Conference on Evolutionary Multi-Criterion Optimization - Volume 10173, EMO 2017, page 685–700, Berlin, Heidelberg, 2017. Springer-Verlag. [68] Kaifeng Yang, Michael Emmerich, André H. Deutz, and Thomas Bäck. Efﬁcient computation of expected hypervolume improvement using box decomposition algorithms. CoRR, abs/1904.12672, 2019. [69] Kaifeng Yang, Michael Emmerich, André Deutz, and Thomas Bäck. Multi-objective bayesian global optimization using expected hypervolume improvement gradient. Swarm and Evolutionary Computation, 44:945 – 956, 2019. ISSN 2210-6502. doi: https://doi.org/10.1016/j.swevo.2018.10.007. URL http: //www.sciencedirect.com/science/article/pii/S2210650217307861. 13[70] Kaifeng Yang, Pramudita Palar, Michael Emmerich, Koji Shimoyama, and Thomas Bäck. A multi- point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. pages 656–663, 07 2019. doi: 10.1145/3321707.3321784. [71] Kaifeng Yang, Pramudita Satria Palar, Michael Emmerich, Koji Shimoyama, and Thomas Bäck. A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, page 656–663, New York, NY , USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10.1145/3321707.3321784. URL https://doi.org/10.1145/3321707.3321784. [72] R. J. Yang, N. Wang, C. H. Tho, J. P. Bobineau, and B. P. Wang. Metamodeling Development for Vehicle Frontal Impact Simulation. Journal of Mechanical Design, 127(5):1014–1020, 01 2005. [73] E. Zitzler, L. Thiele, M. Laumanns, C. M. Fonseca, and V . G. da Fonseca. Performance assessment of multiobjective optimizers: an analysis and review. IEEE Transactions on Evolutionary Computation, 7(2): 117–132, 2003. 14Appendix to: Differentiable Expected Hypervolume Improvement for Parallel Multi-Objective Bayesian Optimization A Derivation of q-Expected Hypervolume Improvement A.1 Hypervolume Improvement via the Inclusion-Exclusion Principle The hypervolume improvement of f(x) within the hyper-rectangle Sk is the volume of Sk ∩∆({f(x)},P,r) and is given by: HVIk ( f(x),lk,uk ) = λM ( Sk ∩∆({f(x)},P,r) ) = M∏ m=1 [ z(m) k −l(m) k ] +, where u(m) k ,l(m) k ,f(m)(x), and z(m) k denote the mth component of the corresponding vector and [·]+ denotes the min(·,0) operation. Summing over all Sk gives the total hypervolume improvement: HVI ( f(x) ) = K∑ k=1 HVIk ( f(x),lk,uk ) = K∑ k=1 λM ( Sk ∩∆({f(x)},P,r) ) = K∑ k=1 M∏ m=1 [ z(m) k −l(m) k ] +. We can extend the HVI computation to the q >1 case using the inclusion-exclusion principle. Principle 1. The inclusion-exclusion principle[13, 59, 9] Given a ﬁnite measure space (B,A,µ) and a ﬁnite sequence of potentially empty or overlapping sets {Ai}i = 1n where Ai ∈A and µ(B) <∞, then, λM ( p⋃ i=1 Ai ) = p∑ j=1 (−1)j+1 ∑ 1≤i1≤...≤ij≤p λM ( Ai1 ∩...∩Aij ) In the context of computing the joint HVI of q new points{f(xi)}q i=1, each subset Ai for i = 1,...,q is the set of points contained in ∆({f(xi)},P,r) — independently of the other q−1 points. λM (Ai) is the hypervolume improvement from the new point f(xi): λM (Ai) = HVI(f(xi)). The union of these subsets is the set of points in the new space dominated by the qnew points: ⋃q i=1 Ai = ⋃q i=1 ∆({f(xi)},P,r). The hypervolume of ⋃q i=1 ∆({f(xi)},P,r) is the hypervolume improvement from the qnew points: HVI({f(xi)}q i=1) = λM ( q⋃ i=1 Ai ) = q∑ j=1 (−1)j+1 ∑ 1≤i1≤...≤ij≤q λM ( Ai1 ∩···∩ Aij ) To compute λM (Ai1 ∩···∩ Aij ), we partition the space covered by Ai1 ∩···∩ Aij across the K hyper- rectangles {Sk}K k=1 and compute the hypervolume of the overlapping space of Ai1 ∩···∩ Aij with each Sk independently. Since {Sk}K k=1 is a disjoint partition, summing overKgives the hypervolume ofAi1 ∩···∩ Aij : λM ( Ai1 ∩···∩ Aij ) = K∑ k=1 λM ( Sk ∩Ai1 ∩···∩ Aij ) This has two advantages. First, the new dominated space Ai can be a non-rectangular polytope, but the intersection Ai ∩Sk is a rectangular polytope, which simpliﬁes computation of overlapping hypervolume. 15Second, the vertices deﬁning the hyper-rectangle encapsulated by Sk ∩Ai1 ∩···∩ Aij are easily derived. The lower bound is simply the lk lower bound of Sk and the upper bound is the component-wise minimum zk,i1,...ij = min [ uk,f(xi1 ),..., f(xij ) ] . Importantly, this is computationally tractable because this speciﬁc approach enables parallelizing computation across all intersections of subsets Ai1 ∩···∩ Aij for 1 ≤ij ≤... ≤ij ≤qand across all Khyper-rectangles. Explicitly, the HVI is computed as: HVI({f(xi)}q i=1) = λM ( p⋃ i=1 Ai ) = q∑ j=1 ∑ 1≤i1≤...≤ij≤q (−1)j+1λM ( Ai1 ∩···∩ Aij ) = K∑ k=1 q∑ j=1 ∑ 1≤i1≤...≤ij≤q (−1)j+1λM ( Sk ∩Ai1 ∩···∩ Aij ) = K∑ k=1 q∑ j=1 ∑ 1≤i1≤...≤ij≤q (−1)j+1λM ( Sk ∩∆({f(xi1 )},P,r) ∩... ∩∆({f(xij )},P,r) ) = K∑ k=1 q∑ j=1 ∑ 1≤i1≤...≤ij≤q (−1)j+1 M∏ m=1 [ z(m) k,i1,...ij −l(m) k ] + = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj −l(m) k ] + where Xj is the superset all subsets of Xcand of size j: Xj = {Xj ⊂Xcand : |Xj|= j}and z(m) k,Xj = z(m) k,i1,...ij for Xj = {xi1 ,..., xij }. A.2 Computing Expected Hypervolume Improvement The above approach for computing HVI assumes we know the true objective values {f(xi)}q i=1. Since we do not know the true function values {f(xi)}q i=1, we compute qEHVI as the expectation over the GP posterior. αqEHVI = E [ HVI({f(xi)}q i=1) ] = ∫ RM HVI({f(xi)}q i=1)df (6) In the sequential setting and under the assumption of independent outcomes, qEHVI is simply EHVI and can be expressed in closed form [ 69]. However when q > 1, there is no known analytical formulation [70]. Instead, we estimate the expectation in (6) using MC integration with samples from the joint posterior P ( f(x1),..., f(xq)|D): αqEHVI = E [ HVI({f(xi)}q i=1) ] ≈ 1 N N∑ t=1 HVI({ft(xi)}q i=1) (7) = 1 N N∑ t=1 K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj,t −l(m) k ] + (8) where {ft(xi)}q i=1 ∼P ( f(x1),..., f(xq)|X,Y ) is the tth sample from the joint posterior over Xcand and z(m) k,Xj,t = min [ uk,minx′∈Xj ft(x′) ] . A.3 Supporting Outcome Constraints Recall that we deﬁned the constrained hypervolume improvement as HVI C (f(x),c(x)) = HVI[f(x)] ·1 [c(x) ≥0]. (9) For q= 1 and assuming independence of the objectives and the constraints, the expected HVI C is the product of the expected HVI and the probability of feasibility (the expectation of 1 [c(x) ≥0]) [22]. However, requiring objectives and constraints to be independent is unnecessary when estimating the expectation with MC integration using samples from the joint posterior. 16In the parallel setting, if all constraints are satisﬁed for all q candidates Xcand = {xi}q i=1, HVI C is simply HVI . If a subset V⊂X cand,V̸= ∅ of the candidates violate at least one of the constraints, then the feasible HVI is the HVI of the set of feasible candidates: HVI C (Xcand) = HVI(Xcand \V). That is, the hypervolume contribution (i.e. the marginal HVI) of an infeasible point is zero. In our formulation, HVI can be computed by multiplying (5) with an additional factor ∏ x′∈Xj ∏V v=1 1 [c(v)(x′) ≥0]: HVI C ({f(xi),c(xi)}q i=1) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj −l(m) k ] + ) ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] ] . (10) The additional factor ∏ x′∈Xj ∏V v=1 1 [c(v)(xa) ≥0] indicates whether all constraints are satisﬁed for all candidates in a given subset Xj. Thus HVI C can be computed in the same fashion as HVI , but with the additional step of setting the HV of all subsets containing x′to zero if x′violates any constraint. We can now again perform MC integration as in (5) to compute the expected constrained hypervolume improvement. In this formulation, the marginal hypervolume improvement from a candidate is weighted by the probability that the candidate is feasible. The marginal hypervolume improvements are highly dependent on the outcomes of the other candidates. Importantly, the MC-based approach enables us to properly estimate the marginal hypervolume improvements across candidates by sampling from the joint posterior. Note that while the expected constrained hypervolume E [ HVI C ({f(xi),c(xi)}q i=1) ] is differentiable, we may not differentiate inside the expectation (hence we cannot expect simply differentiating (10) on the sample-level to provide proper gradients). We therefore replace the indicator with a sigmoid function with temperature parameter ϵ, which provides a differentiable relaxation 1 [c(v)(x′) ≥0] ≈s(c(v)(x′); ϵ) := 1 1 + exp(−c(v)(x′)/ϵ) (11) that becomes exact in the limit ϵ↘0. As in the unconstrained parallel scenario, there is no known analytical expression for the expected feasible hypervolume improvement. Therefore, we again use MC integration to approximate the expectation: αqEHVI C (x) = E [ HVI C ({f(xi),c(xi)}q i=1) ] (12a) ≈ 1 N N∑ t=1 HVI C ({ft(xi),ct(xi)}q i=1) (12b) ≈ 1 N N∑ t=1 K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj,t −l(m) k ] + ) ∏ x′∈Xj V∏ v=1 s(c(v)(x′); ϵ) ] (12c) A.3.1 Inclusion Exclusion principle for HVI C Equation (10) holds when the indicator function because HVI C is equivalent to HVI with the subset of feasible points. However, the sigmoid approximation can result in non-zero error. The error function ε: 2Xcand →R can be expressed as ε(X) = ∏ x′∈X V∏ v=1 1 [c(x′) >0] − ∏ x′∈X V∏ v=1 s(c(x′),ϵ) The error function gives a value to each to each element of 2Xcand . Weight functions have been studied in conjunction with the inclusion-exclusion principle [56], but under the assumption of that the weight of a set is the sum of the weights of its elements: w(A) = ∑ a∈A w(a). In our case, the weight function of a set Ais the product the weights of its elements. There, it is not obvious whether the inclusion-exclusion principle will hold in this case. Theorem 1. Given a feasible Pareto frontPfeas, a partitioning {(lk,uk}K k=1 of the objective space RM that is not dominated by the Pfeas, then for a set of points Xcand with objective values f(Xcand) and constraint values c(Xcand), HVI C (f(Xcand),c(Xcand),P,r) = HVI(f′(Xcand),P′,r′) where f′(Xcand) is the set of objective-constraint vectors for each candidate point f′(x) ∈RM+V , P′is the set of vectors [f(1)(x),...,f (M)(x),0V ] ∈RM+V , and r′= [r(1),...,r (M),0V ] ∈RM+V . Proof. Recall equation 10, HVI C ({f(xi),c(xi)}q i=1) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj −l(m) k ] + ) ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] ] . 17Note that the constraint product ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] = V∏ v=1 ∏ x′∈Xj 1 [c(v)(x′) ≥0] = V∏ v=1 min x′∈Xj 1 [c(v)(x′) ≥0] = V∏ v=1 min [ 1, min x′∈Xj 1 [c(v)(x′) ≥0] ] = V∏ v=1 [ min [ 1, min x′∈Xj 1 [c(v)(x′) ≥0] ] −0 ] . (13) For v = 1 ,...,V , k = 1 ,...K, let l(M+v) k = 0 and u(M+v) k = 1 . Then, substituting into the following expression from Equation 13 gives min [ 1, min x′∈Xj 1 [c(v)(x′) ≥0] ] = min [ u(M+v) k , min x′∈Xj 1 [c(v)(x′) ≥0] ] Recall from Section 4, that zis deﬁned as: zk := min [ uk,f(x) ] . The high-level idea is that if we consider the indicator of the slack constraints 1 [c(v)(x′) ≥0] as objectives, then the above expression is consistent with the deﬁnition of zat the beginning of section 4. For v= 1,...,V , z(M+v) k,Xj = min [ 1, min x′∈Xj 1 [c(v)(x′) ≥0] ] Thus, ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] = V∏ v=1 [ min [ 1, min x′∈Xj 1 [c(v)(x′) ≥0] ] −0 ] = V∏ v=1 [ z(M+v) k,Xj −l(M+v) k ] + Returning to the HVI C equation, we have HVI C ({f(xi),c(xi)}q i=1) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj −l(m) k ] + ) ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] ] = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj −l(m) k ] + ) M+V∏ v=M+1 [ z(v) k,Xj −l(M+v) k ] + ] = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [M+V∏ m=1 [ z(m) k,Xj −l(m) k ] + ] (14) Now consider the case when a sigmoid approximation 1 [c(v)(x′) ≥0] ≈s(c(v)(x′); ϵ) is used. The only change to Equation 14 is that z(m) k,Xj ≈ˆz(m) k,Xj = min [ u(M+v) k , min x′∈Xj S[c(v)(x′),ϵ] ] . If S[c(v)(x′),ϵ] = 1 [c(v)(x′) ≥0] for all v,x′, then HVI is computed exactly without approximation error. If S[c(v)(x′),ϵ]1 [c(v)(x′) ≥0] for any v,x′, then there is approximation error: the hypervolume improvement from all subsets containing x′is proportional to ∏V v=1 minx′∈X s(c(x′),ϵ). Since the constraint outcomes are directly considered as components in the hypervolume computation, the inclusion-exclusion principle incorporates the approximate indicator properly. 18A.4 Complexity Recall from Section 3.3 that, given posterior samples, the time complexity on a single-threaded machine is T1 = O(MNK(2q −1)). The space complexity required for maximum parallelism is also is T1 (ignoring the space required by the models), which does limit scalability to larger M and q, but difﬁculty scaling to large M is a known limitaiton of EHVI [69]. To reduce memory load, rectangles could be materialized and processed in chunks at the cost of additional runtime. In addition, our implementation of qEHVI uses the box decomposition algorithm from Couckuyt et al. [11], but we emphasize qEHVI is agnostic to the choice of partitioning algorithm and using a more efﬁcient partitioning algorithm (e.g. [69, 17, 41]) may signiﬁcantly improve memory footprint on GPU and enable larger using qin many scenarios. B Error Bound on Sequential Greedy Approximation If the acquisition function L(Xcand) is a normalized, monotone, submodular set function (where submodular means that the increase in L(Xcand) is non-increasing as elements are added to Xcand and normalized means that L(∅) = 0), then the sequential greedy approximation of Lenjoys regret of no more than 1 e L∗, where L∗is the optima of L[23]. We have αqEHVI (Xcand) = L(Xcand) = Ef ( HVI [ f(Xcand) ]) . Since HVI is a submodular set function [24] and the expectation of a stochastic submodular function is also submodular [ 2], αqEHVI (Xcand) is also submodular and therefore its sequential greedy approximation enjoys regret of no more than 1 e α∗ qEHVI . Using the result from Wilson et al. [65], the MC-based approximation ˆαqEHVI (Xcand) = ∑N t=1 HVI [ ft(Xcand) ] also enjoys the same regret bound since HVI is a normalized submodular set function.7 C Convergence Results For the purpose of stating our convergence results, we recall some concepts and notation from Balandat et al. [5]. First, consider a sample {ft(x1)}q i=1 from the multi-output posterior of the GP surrogate model. Let x∈Rqd be the stacked set of candidates Xcand and let ft(x) := [ft(x1)T ,...,f t(xq)T ]T be the stacked set of corresponding objective vectors. It is well known that, using the reparameterization trick, we can write ft(x) = µ(x) + L(x)ϵt, (15) where µ: Rqd →RqM is the mean function of the multi-output GP, L(x) ∈RqM×qM is a root decomposition (typically the Cholesky decomposition) of the multi-output GP’s posterior covarianceΣ(x) ∈RqM×qM , and ϵt ∈RqM with ϵt ∼N(0,IqM ). For x∈X , consider the MC-approximation ˆαN qEHVI (x) from (5). Denote by ∇x ˆαN qEHVI (x) the gradient of ˆαN qEHVI (x), obtained by averaging the gradients on the sample-level: ∇x ˆαN qEHVI (x) := 1 N N∑ t=1 ∇xHVI({ft(xi)}q i=1) (16) Let α∗ qEHVI := max x∈XαqEHVI (x) denote the maximum of the true acquisition function qEHVI , and let X∗:= arg maxx∈XαqEHVI (x) denote the set of associated maximizers. Theorem 2. Suppose that Xis compact and thatfhas a Multi-Output Gaussian Process prior with continuously differentiable mean and covariance functions. If the base samples {ϵt}N t=1 are drawn i.i.d. from N(0,IqM ), and if ˆx∗ N ∈arg maxx∈X ˆαN qEHVI (x), then (1) αqEHVI (ˆx∗ N ) →α∗ qEHVI a.s. (2) dist(ˆx∗ N ,X∗) →0 a.s. In addition to the almost sure convergence in Theorem 2, deriving a result on the convergence rate of the optimizer, similar to the one obtained in [5], should be possible. We leave this to future work. Moreover, the results in Theorem 2 can also be extended to the situation in which the base samples are generated using a particular class of randomized QMC methods (see similar results in [5]). Proof. We consider the setting from Balandat et al. [5, Section D.5]. Let ϵ ∼N(0,IqM ), so that we can write the posterior over outcome mat xas the random variable f(m)(x,ϵ) = S{ij,m}(µ(x) + L(x)ϵ), where µ(x) 7As noted in Wilson et al. [65], submodularity technically requires the search space Xto be ﬁnite, whereas in BO, it will typically be inﬁnite. Wilson et al. [65] note that in similar scenarios, submodularity has been extended to inﬁnite sets X(e.g. Srinivas et al. [58]). 19and L(x) are the (vector-valued) posterior mean and the Cholesky factor of posterior covariance, respectively, and S{ij,m}is an appropriate selection matrix (in particular, ∥S{ij,m}∥∞≤1 for all ij and m). Let A(x,ϵ) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj (ϵ) −l(m) k ] + where z(m) k,Xj (ϵ) = min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] and Xj = {xi1 ,..., xij }. Following [5, Theorem 3], we need to show that there exists an integrable function ℓ: Rq×M ↦→R such that for almost every ϵand all x,y⊆X,x,y∈Rq×d, |A(x,ϵ) −A(y,ϵ)|≤ ℓ(ϵ)∥x−y∥. (17) Let us deﬁne ˜akmjXj (x,ϵ) := [ min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] −l(m) k ] + . Linearity implies that it sufﬁces to show that this condition holds for ˜A(x,ϵ) := M∏ m=1 ˜akmjXj (x,ϵ) = M∏ m=1 [ min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] −l(m) k ] + (18) for all k, j, and Xj. Observe that ˜akmjXj (x,ϵ) ≤ ⏐⏐⏐min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] −l(m) k ⏐⏐⏐ ≤|l(m) k |+ ⏐⏐⏐min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ]⏐⏐⏐. Note that if u(m) k = ∞, then min[u(m) k ,f(x,ϵ)(m) i1 ,...f(m)(xij ,ϵ)] = min[f(m)(xi1 ,ϵ),...f(m)(xij ,ϵ)]. If u(m) k < ∞, then min[u(m) k ,f(m)(xi1 ,ϵ),...f(m)(xij ,ϵ)] < ⏐⏐min[f(m)(xi1 ,ϵ),...f(m)(xij ,ϵ)] ⏐⏐+ ⏐⏐u(m) k ⏐⏐. Let w(m) k = u(m) k if u(m) k <∞and 0 otherwise. Then ˜akmjXj (x,ϵ) ≤|l(m) k |+ |w(m) k |+ ⏐⏐min [ f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ]⏐⏐ ≤|l(m) k |+ |w(m) k |+ ∑ i1,...,ij ⏐⏐f(m)(xij ,ϵ) ⏐⏐. We therefore have that |˜akmjXj (x,ϵ)|≤| l(m) k |+ |w(m) k |+ |Xj| ( ∥µ(m)(x)∥+ ∥L(m)(x)∥∥ϵ∥ ) for all k,m,j,X j, where |Xj|denotes the cardinality of the set Xj. Under our assumptions (compactness of X, continuous differentiability of mean and covariance function), both µ(x) and L(x), as well as their respective gradients w.r.t. x, are uniformly bounded. In particular there exist C1,C2 <∞such that |˜akmjXj (x,ϵ)|≤ C1 + C2∥ϵ∥ for all k,m,j,X j. Dropping indices k,j,X j for simplicity, observe that ⏐⏐˜A(x,ϵ) −˜A(y,ϵ) ⏐⏐= ⏐⏐˜a1(x,ϵ)˜a2(x,ϵ) −˜a1(y,ϵ)˜a2(y,ϵ) ⏐⏐ (19a) = ⏐⏐˜a1(x,ϵ) ( ˜a2(x,ϵ) −˜a2(y,ϵ) ) + ˜a2(y,ϵ) ( ˜a1(x,ϵ) −˜a1(y,ϵ) )⏐⏐ (19b) ≤|˜a1(x,ϵ)| ⏐⏐˜a2(x,ϵ) −˜a2(y,ϵ) ⏐⏐+ |˜a2(y,ϵ)| ⏐⏐˜a1(x,ϵ) −˜a1(y,ϵ) ⏐⏐. (19c) Furthermore, |˜akmjXj (x,ϵ) −˜akmjXj (y,ϵ)|≤ ∑ i1,...,ij ⏐⏐S{ij,m}(µ(x) + L(x)ϵ) −S{ij,m}(µ(y) + L(y)ϵ) ⏐⏐ ≤|Xj| ( ∥µ(x) −µ(y)∥+ ∥L(x) −L(y)∥∥ϵ∥ ) . Since µand Lhave uniformly bounded gradients, they are Lipschitz. Therefore, there exist C3,C4 <∞such that |˜akmjXj (x,ϵ) −˜akmjXj (y,ϵ)|≤ (C3 + C4∥ϵ∥)∥x−y∥ 20for all x,y,k,m,j,X j. Plugging this into (19) above, we ﬁnd that ⏐⏐˜A(x,ϵ) −˜A(y,ϵ) ⏐⏐≤2 ( C1C3 + (C1C4 + C2C3)∥ϵ∥+ C2C4∥ϵ∥2 ) ∥x−y∥ for all x,yand ϵ. For M > 2 we generalize the idea from (19), making sure to telescope the respective expressions. It is not hard to see that with this, there exist C <∞such that ⏐⏐˜A(x,ϵ) −˜A(y,ϵ) ⏐⏐≤C M∑ m=1 ∥ϵ∥m∥x−y∥ Letting ℓ(ϵ) := C∑M m=1 ∥ϵ∥m, we observe that ℓ(ϵ) is integrable (since all absolute moments exist for the Normal distribution). The result now follows from in Balandat et al. [5, Theorem 3]. Besides the above convergence result, we can also show that the sample average gradient of the MC approximation of qEHVI is an unbiased estimator of the true gradient of qEHVI: Proposition 1. Suppose that the GP mean and covariance function are continuously differentiable. Suppose further that the candidate set xhas no duplicates, and that the sample-level gradients ∇xHVI({ft(xi)}q i=1) are obtained using the reparameterization trick as in [5]. Then E [ ∇x ˆαN qEHVI (x) ] = ∇xαqEHVI (x), (20) that is, the averaged sample-level gradient is an unbiased estimate of the gradient of the true acquisition function. Proof. This proof follows the arguments Wang et al.[63, Theorem 1], which leverages Glasserman[31, Theorem 1]. We verify the conditions of Glasserman [31, Theorem 1] below. Using the arguments from [5], we know that, under the assumption of differentiable mean and covariance functions, the samples ft(x) are continuously differentiable w.r.t. x(since there are no duplicates, and thus the covariance Σ(x) is non-singular). Hence, Glasserman [31, A1] is satisﬁed. Furthermore, it is easy to see from(1) that HVI({f(xi)}q i=1) is a.s. continuous and is differentiable w.r.t. ft(x) on RM , except on the edges of the hyper-rectangle decomposition {Sk}K k=1 of the non-dominated space, which satisﬁes [31, A3]. The set of points deﬁned by the union of these edges clearly has measure zero under any non-degenerate (non-singular covariance) GP posterior on RM , so Glasserman [31, A4] holds. Therefore Glasserman [31, Lemma 2] holds, so HVI({f(xi)}q i=1) is a.s. piece-wise differentiable w.r.t. x. Lastly, we need to show that the result in Glasserman [31, Lemma 3] holds: E [ sup xci /∈˜D |A′(x,ϵ)| ] <∞. As in Wang et al.[63, Theorem 1], we ﬁx xexcept for xci where xci is the cth component of the ith point, We need to show that E [ supxci /∈˜D |A′(x,ϵ)| ] <∞. By linearity, it sufﬁces to show that E [ supxci /∈˜D |˜A′(x,ϵ)| ] <∞. We have E [ sup xci /∈˜D |˜A′(x,ϵ)| ] = E [ sup xci /∈˜D ⏐⏐⏐⏐ ∂˜A(x,ϵ) ∂xci ⏐⏐⏐⏐ ] . Consider the M = 2 case. We have ˜A(x,ϵ) = a1(x,ϵ)a2(x,ϵ), where am(x,ϵ) = [ min [ u(m) k ,f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] −l(m) k ] + . The partial derivative of ˜A(x,ϵ) with respect to xci is ∂˜A(x,ϵ) ∂xci = ∂a1(x,ϵ) ∂xci a2(x,ϵ) + a1(x,ϵ)∂a2(x,ϵ) ∂xci , and therefore ⏐⏐⏐∂˜A(x,ϵ) ∂xci ⏐⏐⏐≤ ⏐⏐⏐∂a1(x,ϵ) ∂xci ⏐⏐⏐· ⏐⏐⏐a2(x,ϵ) ⏐⏐⏐+ ⏐⏐⏐a1(x,ϵ) ⏐⏐⏐· ⏐⏐⏐∂a2(x,ϵ) ∂xci ⏐⏐⏐ Since we are only concerned with xci /∈ ˜D, am(x,ϵ) = [ min [ f(m)(xi1 ,ϵ),...,f (m)(xij ,ϵ) ] −l(1) k ] + . 21As in the proof of Theorem 2, we write the posterior over outcome mat xas the random variable f(m)(x,ϵ) = S{ij,m}(µ(x) + L(x)ϵ), where ϵ ∼N(0,IqM ) and S{ij,m}is an appropriate selection matrix. With this, am(x,ϵ) = [ min [ S{i1,1} ( µ(x) + L(x)ϵ ) ,...,S {ij,1} ( µ(x) + L(x)ϵ )] −l(1) k ] + . Since the interval X is compact and the mean, covariance, and Cholesky factor of the covariance µ(x),C(x),L(x) are continuously differentiable, for all mwe have sup xci ⏐⏐⏐⏐ ∂µ(m)(xa) ∂xci ⏐⏐⏐⏐= µ∗,(m) a <∞, sup xci ⏐⏐⏐⏐ ∂L(m)(x) ∂xci ⏐⏐⏐⏐= L∗,(m) ca <∞. Let µ(m) ∗∗ = maxa µ∗,(m) a , L(m) ∗∗ = maxa,b L∗,(m) ab (x), where L(m) ab is the element at row a, column bin L(m), the Cholesky factor for outcome m. Let ϵ(m) ∈Rq denote the vector of i.i.d. N(0,1) samples corresponding to outcome m. Then we have⏐⏐⏐⏐ ∂ ∂xci [ [min [ S{i1,1} ( µ(x) + L(x)ϵ ) ,...,S {ij,1} ( µ(x) + L(x)ϵ )] −l(1) k ] + ⏐⏐⏐⏐ ≤ ⏐⏐⏐ [ µ(m) ∗∗ + L(m) ∗∗ ||ϵ(m)||1 −l(m) k ] + ⏐⏐⏐ ≤ ⏐⏐⏐µ(m) ∗∗ + L(m) ∗∗ ||ϵ(m)||1 ⏐⏐⏐+ ⏐⏐⏐l(m) k ⏐⏐⏐. Under our assumptions (compactness of X, continuous differentiability of mean and covariance function) both µ(x) and L(x), as well as their respective gradients, are uniformly bounded. In particular there exist C(m) 1 ,C(m) 2 <∞such that ⏐⏐S{a,m} ( µ(x) + L(x)ϵ ) −l(m) k ⏐⏐≤C(m) 1 + C(m) 2 ||ϵ(m)||1 for all a= i1,...,i j. Hence, ⏐⏐⏐⏐ ∂˜A(x,ϵ) ∂xci ⏐⏐⏐⏐≤ [⏐⏐⏐µ(1) ∗∗ + C(1) ∗∗||ϵ(1)||1 ⏐⏐⏐+ ⏐⏐⏐l(1) k ⏐⏐⏐ ][ C(2) 1 + C(2) 2 ||ϵ(2)||1 ] + [ C(1) 1 + C(1) 2 ||ϵ(1)||1 ][⏐⏐⏐µ(2) ∗∗ + C(2) ∗∗||ϵ(2)||1 ⏐⏐⏐+ ⏐⏐⏐l(2) k ⏐⏐⏐ ] Since ϵis absolutely integrable, E (⏐⏐⏐⏐ ∂˜A(x,ϵ) ∂xci ⏐⏐⏐⏐ ) <∞. Hence, E [ supxci /∈˜D |A′(x,ϵ)| ] <∞. This can be extended to M >2 in the same manner using the product rule to obtain E (∂˜A(x,ϵ) ∂xci ) ≤ M∑ m=1 ([⏐⏐⏐µ(m) ∗∗ + C(m) ∗∗ E[||ϵ(m)||1] ⏐⏐⏐+ ⏐⏐⏐l(1) k ⏐⏐⏐ ] M∏ n=1,n̸=m [ C(n) 1 + C(n) 2 E[||ϵ(n)||1] ]) ≤ M∑ m=1 ([⏐⏐⏐µ(m) ∗∗ + π 2 qC(m) ∗∗ ⏐⏐⏐+ ⏐⏐⏐l(1) k ⏐⏐⏐ ] M∏ n=1,n̸=m [ C(n) 1 + π 2 qC(n) 2 ] ]) . Hence, E [ supxci /∈˜D |A′(x,ϵ)| ] <∞for M ≥2 and Glasserman [31, Theorem 1] holds. 22D Monte-Carlo Approximation Figure 5b shows the gradient of analytic EHVI and the MC estimator qEHVI on slice of a 3-objective problem. Even using only N = 32 QMC samples, the average sample gradient has very low variance. Moreover, ﬁxing the base samples also greatly reduces the variance without introducing bias. 0.0 0.1EHVI MC,/uni00A0N=32 analytic qMC,/uni00A0N=32 analytic 0.00 0.25 0.50 0.75 1.00 0.0 0.1EHVI MC,/uni00A0N=32/uni00A0(fixed) analytic 0.00 0.25 0.50 0.75 1.00 qMC,/uni00A0N=32/uni00A0(fixed) analytic (a) A comparison of the analytic EHVI acquisition function and the MC-based qEHVI for q= 1. 0.1 0.0 0.1 /uni00A0EHVI MC,/uni00A0N=32 analytic qMC,/uni00A0N=32 analytic 0.00 0.25 0.50 0.75 1.00 0.1 0.0 0.1 /uni00A0EHVI MC,/uni00A0N=32/uni00A0(fixed) analytic 0.00 0.25 0.50 0.75 1.00 qMC,/uni00A0N=32/uni00A0(fixed) analytic (b) A comparison of the exact gradient of analytic EHVI and the exact sample average gradient of the MC-based qEHVI for q= 1. Figure 5: A comparison of (a) the analytic EHVI and MC-based qEHVI for q = 1 and (b) a comparison of the exact gradient ∇αEHVI of analytic EHVI and average sample gradient of the MC-estimator ∇ˆαqEHVI over a slice of the input space on a DTLZ2 problem (q= 1, M = 3, d= 6) [15]. x(0) is varied across 0 ≤λ≤1, while x(i) for 1,...D are held constant. In each of (a) and (b), the top row show qEHVI where the (quasi-)standard normal base samples are resampled for each value of x(0). The solid line is one sample average (across (q)MC samples) and the shaded area is the mean plus 2 standard errors across 50 repetitions. The bottom row uses the same base samples for evaluating each test point and the sample average for each of 50 repetitions is plotted. E Experiment Details E.1 Algorithms For TS-TCH, we draw a sample from the joint posterior over a discrete set of 1000dpoints sampled from a scrambled Sobol sequence. For PESMO, we follow [27] and use a Pareto set of size 10 for each sampled GP, which is optimized over a discrete set of 1000dpoints sampled from a scrambled Sobol sequence. The current 23Table 2: Reference points for all benchmark problems. Assuming minimization. In our benchmarks, equivalently maximize the negative objectives and multiply the reference points by -1. PROBLEM REFERENCE POINT BRANIN CURRIN (18.0, 6.0) DTLZ2 (1.1,..., 1.1) ∈RM ABR (-150.0, 3500.0, 5.1) VEHICLE CRASH SAFETY (1864.72022, 11.81993945, 0.2903999384) CONSTRAINED BRANIN CURRIN (90.0, 10.0) C2-DTLZ2 (1.1,..., 1.1) ∈RM Pareto front is approximated by optimizing the posterior means over a grid as is done in Garrido-Merchán and Hernández-Lobato [26, 27]. For SMS-EGO, we use the observed Pareto front. All acquisition functions are optimized with L-BFGS-B (with a maximum of 200 iterations); SMS-EGO [53] and PESMO [26] use gradients approximated by ﬁnite differences and all other methods use exact gradients. For all methods, each outcome is modeled with an independent Gaussian process with a Matern 5/2 ARD kernel. The methods implemented in Spearmint use a fully Bayesian treatment of the hyperparameters with 10 samples from posterior over the hyperparamters, and the methods implemented in BoTorch use maximum a posteriori estimates of the GP hyperparameters. All methods are initialized with 2(d+ 1)points from a scrambled Sobol sequence. qPAREGO and qEHVI use N = 128 QMC samples. E.1.1 Reference point speciﬁcation There is a large body of literature on the effects of reference point speciﬁcation [4, 35, 36]. The hypervolume indicator is sensitive to speciﬁed the reference point: a reference point that is far away from the Pareto front will favor extreme points, where as reference point that is close to the Pareto front gives more weight to less extreme points [36]. Sensitivity to the reference point is affects both the evaluation of different MO methods and the utility function for methods that rely HV. In practice, a decision maker may be able to specify a reference point that satisﬁes their preference with domain knowledge. If a reference point is provided by the decision maker, previous work has suggested heuristics for choosing reference points for use in an algorithm’s utility function [35, 53]. We follow previous work [69, 68] and assume that the reference point is known. We also considered (but did not use in our experiments) a dynamic reference point strategy where at each BO iteration, the reference point is selected to be a point slightly worse than the nadir (component-wise minimum) point of the current observed Pareto front for computing the acquisition function: r = ynadir −0.1 ·|ynadir| where ynadir = ( miny(1)∈D(1) y(1),..., miny(m)∈D(m) y(m)) . This reference point is used in SMS-EMOA in Ishibuchi et al. [35]), and we ﬁnd similar average performance (but higher variance) on problems to using a known reference point with continuous Pareto fronts. If the Pareto front is discontinuous, then it is possible not all sections of the Pareto front will be reached. E.1.2 qPAREGO Previous work has only considered unconstrained sequential optimization with ParEGO [40, 7] and ParEGO is often optimized with gradient-free methods [ 53]. To the best of our knowledge, qPAREGO is the ﬁrst to support parallel and constrained optimization. Moreover, we compute exact gradients via auto-differentiation for acquisition optimization. ParEGO is typically implemented by applying augmented Chebyshev scalarization and modeling the scalarized outcome [40]. However, recent work has shown that composite objectives offer improved optimization performance [3]. qPAREGO uses a MC-based Expected Improvement [38] acquisition function, where the objectives are modeled independently and the augmented Chebyshev scalarization [40] is applied to the posterior samples as a composite objective. This approach enables the use of sequential greedy optimization of qcandidates with proper integration over the posterior at the pending points. Importantly, the sequential greedy approach allows for using different random scalarization weights for selecting each of the q candidates. qPAREGO is extended to the constrained setting by weighting the EI by the probability of feasibility [25]. We estimate the probability of feasiblity using the posterior samples and approximate the indicator function with a sigmoid to maintain differentiablity as in constrained qEHVI . qPAREGO is trivially extended to the noisy setting using Noisy Expected Improvement [43, 5], but we use Expected Improvement in our experiments as all of the problems are noiseless. E.2 Benchmark Problems The details for the benchmark problems below assume minimization of all objectives. Table 2 provides the reference points used for all benchmark problems. 24Branin-Currin f(1)(x′ 1,x′ 2) = (x2 −5.1 4π2 x2 1 + 5 πx1 −r)2 + 10(1 − 1 8π) cos(x1) + 10 f(2)(x1,x2) = [ 1 −exp ( − 1 (2x2) )]2300x3 1 + 1900x2 1 + 2092x1 + 60 100x3 1 + 500x2 1 + 4x1 + 20 where x1,x2 ∈[0,1], x′ 1 = 15x1 −5, and x′ 2 = 15x2. The constrained Branin-Currin problem uses the following disk constraint from [29]: c(x′ 1,x′ 2) = 50 −(x′ 1 −2.5)2 −(x′ 2 −7.5)2) ≥0 DTLZ2 The objectives are given by [15]: f1(x) = (1 + g(xM )) cos (π 2 x1 ) ··· cos (π 2 xM−2 ) cos (π 2 xM−1 ) f2(x) = (1 + g(xM )) cos (π 2 x1 ) ··· cos (π 2 xM−2 ) sin (π 2 xM−1 ) f3(x) = (1 + g(xM )) cos (π 2 x1 ) ··· sin (π 2 xM−2 ) ... fM (x) = (1 + g(xM )) sin (π 2 x1 ) where g(x) = ∑ xi∈xM (xi −0.5)2,x∈[0,1]d,and xM represents the last d−M + 1 elements of x. The C2-DTLZ2 problem adds the following constraint [16]: c(x) = −min [ M min i=1 ( (fi(x) −1)2 + M∑ j=1,j=i (f2 j −r2) ) , ( M∑ i=1 ( (fi(x) − 1√ M )2 −r2))] ≥0 Vehicle Crash Safety The objectives are given by [60]: f1(x) = 1640.2823 + 2.3573285x1 + 2.3220035x2 + 4.5688768x3 + 7.7213633x4 + 4.4559504x5 f2(x) = 6.5856 + 1.15x1 −1.0427x2 + 0.9738x3 + 0.8364x4 −0.3695x1x4 + 0.0861x1x5 + 0.3628x2x4 + 0.1106x2 1 −0.3437x2 3 + 0.1764x2 4 f3(x) = −0.0551 + 0.0181x1 + 0.1024x2 + 0.0421x3 −0.0073x1x2 + 0.024x2x3 −0.0118x2x4 −0.0204x3x4 −0.008x3x5 −0.0241x2 2 + 0.0109x2 4 where x∈[1,3]5. Policy Optimization for Adaptive Bitrate Control The controller is given by: at = x0 ˆzbd,t + x2zbf,t + x3, where ˆzbd,t = ∑ ti<t zbd,ti exp(−x1ti) ∑ ti<t exp(−x1ti) is estimated bandwidth at time tusing an exponential moving average, zbf,t is the buffer occupancy at time t, and x0,...x3 are the parameters we seek to optimize. We evaluate each policy on a set of 400 videos, where the number of time steps (chunks) in each video stream trajectory depends on the size of the video. 25Table 3: Acquisition Optimization wall time in seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz) and on a GPU (Tesla V100-SXM2-16GB). The mean and two standard errors are reported. NA indicates that the algorithm does not support constraints. CPU CONSTRAINED BRANIN CURRIN DTLZ2 PESMO ( q=1) NA 278.53 (±25.66) SMS-EGO ( q=1) NA 104.26 (±7.66) TS-TCH ( q=1) NA 52.55 (±0.06) qPAREGO ( q=1) 2.4 (±0.37) 4 .68 (±0.46) EHVI ( q=1) NA 3.58 (±0.28) qEHVI ( q=1) 5.69 (±0.43) 5 .95 (±0.45) GPU CONSTRAINED BRANIN CURRIN DTLZ2 TS-TCH ( q=1) NA 0.25 (±0.00) TS-TCH ( q=2) NA 0.27 (±0.00) TS-TCH ( q=4) NA 0.28 (±0.00) TS-TCH ( q=8) NA 0.32 (±0.01) qPAREGO ( q=1) 3.52 (±0.34) 9 .04 (±0.93) qPAREGO ( q=2) 6.0 (±0.56) 14 .23 (±1.55) qPAREGO ( q=4) 12.07 (±0.98) 40 .5 (±3.21) qPAREGO ( q=8) 33.1 (±3.32) 84 .15 (±6.9) EHVI ( q=1) NA 84.15 (±6.9) qEHVI ( q=1) 5.61 (±0.17) 10 .21 (±0.58) qEHVI ( q=2) 19.06 (±5.88) 17 .75 (±0.97) qEHVI ( q=4) 29.26 (±2.01) 40 .41 (±2.78) qEHVI ( q=8) 91.56 (±5.51) 106 .51 (±7.69) F Additional Empirical Results F.1 Additional Sequential Optimization Results We include results for an additional synthetic benchmark: the DTLZ2 problem from the MO literature [ 15] (d= 6,M = 2). Figure 6 shows that qEHVI outperforms all other baseline algorithms on the DTLZ2 in terms of sequential optimization performance with competitive wall times as shown in 3. 0 20 40 60 80 100 Function/uni00A0Evaluations 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4 log/uni00A0HV/uni00A0DifferenceSobol EHVI qEHVI qParEGO TS/uni00ADTCH PESMO SMS/uni00ADEGO Figure 6: Optimization performance on the DTLZ2 synthetic function (d= 6,M = 2). F.2 Performance with Increasing Parallelism Figure 7 shows that that the performance of qEHVI performance does not degrade substantially, whereas performance does degrade for qPAREGO and TS-TCH on some benchmark problems. We include results for all problems in Section 5 and Appendix F.1 as well as a Constrained Branin-Currin problem (which is described in Appendix E.2). 260 20 40 60 80 100 Batch/uni00A0Iteration 0.0 0.5 1.0 1.5 2.0log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (a) VEHICLE SAFETY 0 20 40 60 80 100 Function/uni00A0Evaluations 0.0 0.5 1.0 1.5 2.0log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (b) VEHICLE SAFETY 0 20 40 60 80 100 Batch/uni00A0Iteration 1.1 1.0 0.9 0.8 0.7 0.6 0.5 0.4 log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (c) C2DTLZ2 0 20 40 60 80 100 Function/uni00A0Evaluations 1.1 1.0 0.9 0.8 0.7 0.6 0.5 0.4 log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (d) C2DTLZ2 0 20 40 60 80 100 Batch/uni00A0Iteration 0.0 0.5 1.0 1.5log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (e) BRANIN CURRIN 0 20 40 60 80 100 Function/uni00A0Evaluations 0.0 0.5 1.0 1.5log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (f) BRANIN CURRIN Figure 7: Optimization performance of parallel acquisition functions over batch BO iterations (left) and function evaluations (right) for benchmark problems in Section 5. 270 20 40 60 80 100 Batch/uni00A0Iteration 0.5 1.0 1.5 2.0 2.5log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (a) CONSTRAINED BRANIN CURRIN 0 20 40 60 80 100 Function/uni00A0Evaluations 0.5 1.0 1.5 2.0 2.5log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (b) CONSTRAINED BRANIN CURRIN 0 20 40 60 80 100 Batch/uni00A0Iteration 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4 log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (c) DTLZ2 ( M = 2,d = 6) 0 20 40 60 80 100 Function/uni00A0Evaluations 1.8 1.6 1.4 1.2 1.0 0.8 0.6 0.4 log/uni00A0HV/uni00A0Difference Sobol/uni00A0q=8 TS/uni00A0q=1 TS/uni00A0q=2 TS/uni00A0q=4 TS/uni00A0q=8 qEHVI/uni00A0q=1 qEHVI/uni00A0q=2 qEHVI/uni00A0q=4 qEHVI/uni00A0q=8 qParEGO/uni00A0q=1 qParEGO/uni00A0q=2 qParEGO/uni00A0q=4 qParEGO/uni00A0q=8 (d) DTLZ2 ( M = 2,d = 6) Figure 8: Optimization performance of parallel acquisition functions over batch BO iterations (left) and function evaluations (right) for additional benchmark problems. 28F.3 Noisy Observations Although neither qEHVI nor any variant of expected hypervolume improvement (to our knowledge) directly account for noisy observations, noisy observations are a practical challenge. We empirically evaluate the performance of all algorithms on a Branin-Currin function where observations have additive, zero-mean, iid Gaussian noise; the unknown standard deviation of the noise is set to be 1% of the range of each objective. Fig 9 shows that qEHVI performs favorably in the presence of noise, besting all algorithms including Noisy qPAREGO (qNParego) (described in Appendix E.1.2), PESMO and TS-TCH, all of which account for noise. 0 20 40 60 80 100 Function/uni00A0Evaluations 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8log/uni00A0HV/uni00A0Difference Sobol EHVI qEHVI qParEGO qNParEGO TS/uni00ADTCH Figure 9: Sequential optimization performance on a noisy Branin-Currin problem. F.4 Approximate Box Decompositions EHVI becomes prohibitively computationally expensive in many scenarios with ≥4 objectives because of the wall time of partitioning the non-dominated space into disjoint rectangles [ 11]. Therefore, in addition to providing an exact binary partitioning algorithm, Couckuyt et al. [11] propose an approximation that terminates the partitioning algorithm when the new additional set of hyper-rectangles in the partitioning has a total hypervolume of less than a predetermined fraction ζof the hypervolume dominated by the Pareto front. While qEHVI is guaranteed to be exact when an exact partitioning of the non-dominated space is used, qEHVI is agnostic to the partitioning algorithm used and is compatible with more scalable approximate methods. We evaluate the performance ofqEHVI with approximation of various ﬁdelities ζon DTLZ2 problems with 3 and 4 objectives (with d = 6 ). ζ = 0 corresponds to an exact partitioning and the approximation is monotonically worse as ζincreases. Larger values of ζdegrade optimization performance (Figure 10), but can result in substantial speedups (Table 4). Even with coarser levels of approximation, qEHVI () performs better than qPAREGO with respect to log hypervolume difference, while achieving wall time improvements of 2-7x compared to exact qEHVI. 0 20 40 60 80 100 Function/uni00A0Evaluations 1.0 0.8 0.6 0.4 0.2 log/uni00A0HV/uni00A0Difference qEHVI/uni00A0( = 10 3) qEHVI/uni00A0( = 10 4) qEHVI/uni00A0( = 10 5) qEHVI/uni00A0( = 10 6) qEHVI/uni00A0(exact) qParEGO (a) 0 20 40 60 80 100 Function/uni00A0Evaluations 0.7 0.6 0.5 0.4 0.3 0.2 0.1 log/uni00A0HV/uni00A0DifferenceqEHVI/uni00A0( = 10 3) qEHVI/uni00A0( = 10 4) qEHVI/uni00A0( = 10 5) qEHVI/uni00A0( = 10 6) qEHVI/uni00A0(exact) qParEGO (b) Figure 10: Optimization performance on DTLZ2 problems (d= 6) with approximate partitioning using various approximation levels ζfor (a) M = 3 objectives and (b) M = 4 objectives. 29CPU DTLZ2 ( M = 3) DTLZ2 ( M = 4) qPAREGO 5.86 (±0.51) 5 .6 (±0.53) qEHVI ( ζ = 10−3) 6.89 (±0.41) 9 .53 (±0.49) qEHVI ( ζ = 10−4) 9.83 (±0.9) 17 .47 (±1.2) qEHVI ( ζ = 10−5) 18.99 (±2.72) 60 .27 (±3.57) qEHVI ( ζ = 10−6) 37.9 (±7.47) 136 .15 (±12.88) qEHVI ( EXACT ) 45.52 (±9.83) 459 .33 (±77.95) Table 4: Acquisition function optimization wall time with approximate hypervolume computation, in seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz). The mean and two standard errors are reported. F.5 Acquisition Computation Time Figure 11 show the acquisition computation time for different M and q. The inﬂection points corresponds to available processor cores becoming saturated. For large M an qon the GPU, memory becomes an issue, but we discuss ways of mitigating the issue in Appendix A.4. 2.5 5.0 7.5 10.0 12.5 15.0 17.5 q 0 1 2 3 4 5 6Acquisition/uni00A0Computation/uni00A0Time/uni00A0(s) M=2/uni00A0(CPU) M=3/uni00A0(CPU) M=4/uni00A0(CPU) M=2/uni00A0(GPU) M=3/uni00A0(GPU) M=4/uni00A0(GPU) Figure 11: Acquisition computation time for different batch sizes qand numbers of objectives M (this excludes the time required to compute the acquisition function given box decomposition of the non-dominated space). This uses N = 512 MC samples, d= 6, |P|= 10, and 20 training points. CPU time was measured on 2x Intel Xeon E5-2680 v4 @ 2.40GHz and GPU time was measured on a Tesla V100-SXM2-16GB GPU using 64-bit ﬂoating point precision. The mean and 2 standard errors over 1000 trials are reported. 30
---------------------------------

Please extract all reference paper titles and return them as a list of strings.
Output:
{
    "reference_titles": [
        "Expected hypervolume improvement with constraints",
        "Stochastic submodular maximization",
        "Bayesian optimization of composite functions",
        "Theory of the hypervolume indicator: Optimal mu-distributions and the choice of the reference point",
        "BoTorch: A Framework for Efﬁcient Monte-Carlo Bayesian Optimization",
        "Max-value entropy search for multi-objective bayesian optimization",
        "Efﬁcient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm",
        "Monte carlo and quasi-monte carlo methods",
        "The inclusion-exclusion principle",
        "Experimental ﬂapping wing optimization and uncertainty quantiﬁcation using limited samples",
        "Towards efﬁcient multiobjective optimization: Multiobjective statistical criterions",
        "Fast calculation of multiobjective probability of improvement and expected improvement criteria for pareto optimization",
        "Propriedades geraes",
        "A fast and elitist multiobjective genetic algorithm: Nsga-ii",
        "Scalable multi-objective optimization test problems",
        "Constrained Multi-objective Evolutionary Algorithm",
        "Efﬁcient computation of the search region in multi-objective optimization",
        "Single- and multiobjective evolutionary opti- mization assisted by gaussian random ﬁeld metamodels",
        "Hypervolume-based expected improvement: Monotonicity properties and exact computation",
        "A Multicriteria Generalization of Bayesian Global Optimization",
        "Computing hypervolume contributions in low dimensions: Asymptotically optimal algorithm and complexity results",
        "A bayesian approach to constrained single- and multi- objective optimization",
        "An analysis of approximations for maximizing submodular set functions—II",
        "Maximizing submodular functions under matroid constraints by multi-objective evolutionary algorithms",
        "Bayesian optimization with inequality constraints",
        "Predictive entropy search for multi-objective bayesian optimization with constraints",
        "Parallel predictive entropy search for multi-objective bayesian optimization with constraints",
        "Targeting solutions in bayesian multi-objective optimization: sequential and batch versions",
        "Kriging Is Well-Suited to Parallelize Optimization",
        "The CMA Evolution Strategy: A Comparing Review",
        "Predictive entropy search for multi-objective bayesian optimization",
        "Faster exact algorithms for computing expected hypervolume improvement",
        "A many-objective test problem for visually examining diversity maintenance behavior in a decision space",
        "How to specify a reference point in hypervolume calculation for fair performance comparison",
        "Lipschitzian optimisation without the lipschitz constant",
        "Efﬁcient global optimization of expensive black-box functions",
        "Auto-Encoding Variational Bayes",
        "Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems",
        "A box decomposition algorithm to compute the hypervolume indicator",
        "Bayesian optimization for policy search via online-ofﬂine experimen- tation",
        "Constrained bayesian optimization with noisy experiments",
        "Multiobjective optimization for crash safety design of vehicles using stepwise regression model",
        "A gpu-based algorithm for a faster hypervolume contribution computation",
        "Neural adaptive video streaming with pensieve",
        "Real-world video adaptation with reinforcement learning",
        "Park: An open platform for learning-augmented computer systems",
        "Differentiating the multipoint expected improvement for optimal batch design",
        "A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations",
        "Automatic differentiation in PyTorch",
        "Multiobjective optimization using gaussian process emulators via stepwise uncertainty reduction",
        "Multiobjective optimization on a limited budget of evaluations using model-assisted s-metric selection",
        "Alternative inﬁll strategies for expensive multi-objective optimisation",
        "Gaussian Processes in Machine Learning",
        "Inclusion-exclusion and characteristic functions",
        "Taking the human out of the loop: A review of bayesian optimization",
        "An easy-to-use real-world multi-objective optimization problem suite",
        "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples",
        "Bayesian optimization for multi-objective optimization and multi-point search",
        "Parallel bayesian global optimization of expensive functions",
        "The reparameterization trick for acquisition functions",
        "Maximizing acquisition functions for bayesian optimization",
        "The parallel knowledge gradient method for batch bayesian optimization",
        "Computing 3-d expected hypervolume improvement and related integrals in asymptotically optimal time",
        "Efﬁcient computation of expected hypervolume improvement using box decomposition algorithms",
        "Multi-objective bayesian global optimization using expected hypervolume improvement gradient",
        "A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization",
        "A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization",
        "Metamodeling Development for Vehicle Frontal Impact Simulation",
        "Performance assessment of multiobjective optimizers: an analysis and review"
    ]
}
